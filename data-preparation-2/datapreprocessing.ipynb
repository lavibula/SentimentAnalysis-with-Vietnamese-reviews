{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Table of contents\n#### 1 noise removal: \npunctuation(dấu câu), stop words (stopwordsVN), URLs and Special Characters, date time, repeating chars\n#### 2 normalization: \nElongation, accent-marks((e.g., convert all variations of \"á\" to a single form)), từ ngữ không chính thống (slang, viết tắt) và các biến thể về chính tả, sửa lỗi chính tả, lowercase, num2word.\n#### 3 word segmentation\n#### 4 handle negation\n#### 5 Xử lí label","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"pip install underthesea pyvi num2words py_vncorenlp pyvi","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:10.314609Z","iopub.execute_input":"2024-04-18T20:02:10.315364Z","iopub.status.idle":"2024-04-18T20:02:35.017755Z","shell.execute_reply.started":"2024-04-18T20:02:10.315327Z","shell.execute_reply":"2024-04-18T20:02:35.016776Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-6.8.0-py3-none-any.whl.metadata (14 kB)\nCollecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting num2words\n  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\nCollecting py_vncorenlp\n  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.10/site-packages (from underthesea) (8.1.7)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from underthesea) (3.2.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from underthesea) (4.66.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from underthesea) (2.31.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.3.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from underthesea) (6.0.1)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (1.7 kB)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words) (0.6.2)\nCollecting pyjnius (from py_vncorenlp)\n  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->underthesea) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (2024.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.11.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (3.2.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nDownloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hDownloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: py_vncorenlp\n  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4305 sha256=253234f6975d52cd2d4bc4f2749828a3555b2d47b4930faf50c661db07b50d9e\n  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\nSuccessfully built py_vncorenlp\nInstalling collected packages: underthesea-core, python-crfsuite, pyjnius, sklearn-crfsuite, py_vncorenlp, num2words, underthesea, pyvi\nSuccessfully installed num2words-0.5.13 py_vncorenlp-0.1.4 pyjnius-1.6.1 python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6 underthesea-6.8.0 underthesea-core-1.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport unicodedata\nfrom underthesea import word_tokenize\nimport re\nimport string","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:35.019720Z","iopub.execute_input":"2024-04-18T20:02:35.020099Z","iopub.status.idle":"2024-04-18T20:02:38.969903Z","shell.execute_reply.started":"2024-04-18T20:02:35.020063Z","shell.execute_reply":"2024-04-18T20:02:38.968559Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Noise removal","metadata":{}},{"cell_type":"code","source":"# Xử lí dấu câu\ndef remove_punctuation(text):\n    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n    text = text.translate(translator)\n    return text\n\ndef remove_diacritics(text):\n    text = unicodedata.normalize('NFD', text)\n    text = ''.join(c for c in text if not unicodedata.combining(c))\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:38.971276Z","iopub.execute_input":"2024-04-18T20:02:38.971857Z","iopub.status.idle":"2024-04-18T20:02:38.979395Z","shell.execute_reply.started":"2024-04-18T20:02:38.971824Z","shell.execute_reply":"2024-04-18T20:02:38.977970Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Stopwords\nimport requests\n\nraw_url = 'https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords.txt'\nresponse = requests.get(raw_url)\n\nif response.status_code == 200:\n    content = response.text\nelse:\n    print('Failed to retrieve the file from GitHub:', response.status_code)\n\n# Stopwords\nsw = content.split('\\n')\ndef remove_stopword(text):\n    text = \" \".join(x for x in text.split() if x not in sw)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:38.982822Z","iopub.execute_input":"2024-04-18T20:02:38.983366Z","iopub.status.idle":"2024-04-18T20:02:39.492923Z","shell.execute_reply.started":"2024-04-18T20:02:38.983321Z","shell.execute_reply":"2024-04-18T20:02:39.491463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# # URLs and special character\n# def clean_text(text):\n#     '''Remove special character, remove links'''\n\n#     text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    \n#     text = re.sub('\\[.*?\\]', '', text)\n# #     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n#     text = text.replace(u'  ', u' ')\n#     text = text.replace(u'\"', u' ')\n#     text = text.replace(u'️', u'')\n    \n#     return text\n\nimport re\n\ndef clean_text(text):\n    # Remove URLs, special characters and date time\n\n    # Remove URLs\n    text = re.sub(r\"https?://\\S+\", \"\", text)\n    \n    # Remove specific special characters\n    text = re.sub(r\"[!@#$%^&*(]\", \"\", text)\n    \n    # Remove dates in the format dd/mm/yyyy or dd-mm-yyyy or dd.mm.yyyy\n    text = re.sub(r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b', '', text)\n\n    # Remove dates in the format dd_mm_yy\n    text = re.sub(r'\\b\\d{1,2}[_]\\d{1,2}[_]\\d{2}\\b', '', text)\n    \n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.494524Z","iopub.execute_input":"2024-04-18T20:02:39.495132Z","iopub.status.idle":"2024-04-18T20:02:39.503231Z","shell.execute_reply.started":"2024-04-18T20:02:39.495092Z","shell.execute_reply":"2024-04-18T20:02:39.501751Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Xử lý Emoji\n#Quy các icon về 2 loại emoj: Tích cực hoặc tiêu cực\ndef process_emojis(text):\n    emojis_list = {\n        \"👹\": \"negative\", \"👻\": \"positive\", \"💃\": \"positive\",'🤙': 'positive ', '👍': 'positive ',\n        \"💄\": \"positive\", \"💎\": \"positive\", \"💩\": \"positive\",\"😕\": \"negative\", \"😱\": \"negative\", \"😸\": \"positive\",\n        \"😾\": \"negative\", \"🚫\": \"negative\",  \"🤬\": \"negative\",\"🧚\": \"positive\", \"🧡\": \"positive\",'🐶':'positive ',\n        '👎': 'negative ', '😣': 'negative ','✨': 'positive ', '❣': 'positive ','☀': 'positive ',\n        '♥': 'positive ', '🤩': 'positive ', 'like': 'positive ', ':))': 'positive ', ':)': 'positive ',\n        'he he': 'positive ','hehe': 'positive ','hihi': 'positive ', 'haha': 'positive ', 'hjhj': 'positive ',\n        ' lol ': 'negative ',' cc ': 'negative ', 'huhu': 'negative ', '><': u'positive ',\n        '💌': 'positive ', '🥰': 'positive ', '🙆' : 'positive ', '😅' : 'negative ',\n        '🤒' : 'negative ', '🤨' : 'negative ', '🤦' : 'negative ', '😬' :'negative ',\n        '🔋' : 'positive ', '💔' : 'negative ', '🤮' : 'negative ', '✋' : 'positive ',\n        '🤣': 'positive ', '🖤': 'positive ', '🤤': 'positive ', ':(': 'negative ', '😢': 'negative ',\n        '❤': 'positive ', '😍': 'positive ', '😘': 'positive ', '😪': 'negative ', '😊': 'positive ',\n        '?': ' ? ', '😁': 'positive ', '💖': 'positive ', '😟': 'negative ', '😭': 'negative ',\n        '💯': 'positive ', '💗': 'positive ', '♡': 'positive ', '💜': 'positive ', '🤗': 'positive ',\n        '^^': 'positive ', '😨': 'negative ', '☺': 'positive ', '💋': 'positive ', '👌': 'positive ',\n        '😖': 'negative ', '😀': 'positive ', ':((': 'negative ', '😡': 'negative ', '😠': 'negative ',\n        '😒': 'negative ', '🙂': 'positive ', '😏': 'negative ', '😝': 'positive ', '😄': 'positive ',\n        '😙': 'positive ', '😤': 'negative ', '😎': 'positive ', '😆': 'positive ', '💚': 'positive ',\n        '✌': 'positive ', '💕': 'positive ', '😞': 'negative ', '😓': 'negative ', '️🆗️': 'positive ',\n        '😉': 'positive ', '😂': 'positive ', ':v': 'positive ', '=))': 'positive ', '😋': 'positive ',\n        '💓': 'positive ', '😐': 'negative ', ':3': 'positive ', '😫': 'negative ', '😥': 'negative ',\n        '😃': 'positive ', '😬': ' 😬 ', '😌': ' 😌 ', '💛': 'positive ', '🤝': 'positive ', '🎈': 'positive ',\n        '😗': 'positive ', '🤔': 'negative ', '😑': 'negative ', '🔥': 'negative ', '🙏': 'negative ',\n        '🆗': 'positive ', '😻': 'positive ', '💙': 'positive ', '💟': 'positive ',\n        '😚': 'positive ', '❌': 'negative ', '👏': 'positive ', ';)': 'positive ', '<3': 'positive ',\n        '🌝': 'positive ',  '🌷': 'positive ', '🌸': 'positive ', '🌺': 'positive ',\n        '🌼': 'positive ', '🍓': 'positive ', '🐅': 'positive ', '🐾': 'positive ', '👉': 'positive ',\n        '💐': 'positive ', '💞': 'positive ', '💥': 'positive ', '💪': 'positive ',\n        '💰': 'positive ',  '😇': 'positive ', '😛': 'positive ', '😜': 'positive ',\n        '🙃': 'negative ', '🤑': 'positive ', '🤪': 'positive ','☹': 'negative ',  '💀': 'negative ',\n        '😔': 'negative ', '😧': 'negative ', '😩': 'negative ', '😰': 'negative ', '😳': 'negative ',\n        '😵': 'negative ', '😶': 'negative ', '🙁': 'negative ', '🎉': 'positive '}\n    for emoji, label in emojis_list.items():\n        text = text.replace(emoji, f'EMO{label.upper()}' )\n        \n    text = ' ' .join(text.split())\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.505517Z","iopub.execute_input":"2024-04-18T20:02:39.505926Z","iopub.status.idle":"2024-04-18T20:02:39.529569Z","shell.execute_reply.started":"2024-04-18T20:02:39.505883Z","shell.execute_reply":"2024-04-18T20:02:39.528036Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Repeating chars\ndef cleaning_repeating_char(text):\n    return re.sub(r'(.)\\1+', r'\\1', text)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.531162Z","iopub.execute_input":"2024-04-18T20:02:39.531570Z","iopub.status.idle":"2024-04-18T20:02:39.541985Z","shell.execute_reply.started":"2024-04-18T20:02:39.531535Z","shell.execute_reply":"2024-04-18T20:02:39.540714Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def noise_removal(text):\n    \n    text = remove_punctuation(text)\n    text = remove_diacritics(text)\n    text = remove_stopword(text)\n    text = clean_text(text)\n    text = process_emojis(text)\n    text = cleaning_repeating_char(text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.544148Z","iopub.execute_input":"2024-04-18T20:02:39.544594Z","iopub.status.idle":"2024-04-18T20:02:39.551962Z","shell.execute_reply.started":"2024-04-18T20:02:39.544556Z","shell.execute_reply":"2024-04-18T20:02:39.550268Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 2. Normalization","metadata":{}},{"cell_type":"code","source":"# Remove các ký tự kéo dài: vd: đẹppppppp\ndef remove_elongated_chars(text):\n    replacements = {\n       'a' : 'àáảãạăằắẳẵặâầấẩẫậ' ,\n       'e' : 'èéẻẽẹêềếểễệ' ,\n       'i' : 'ìíỉĩị' ,\n       'o' : 'òóỏõọôồốổỗộơờớởỡợ' ,\n       'u' : 'ùúủũụưừứửữự' ,\n       'y' : 'ỳýỷỹỵ' ,\n       'd' : 'đ' ,\n       'A' : 'ÀÁẢÃẠĂẰẮẲẴẶÂẦẤẨẪẬ' ,\n       'E' : 'ÈÉẺẼẸÊỀẾỂỄỆ' ,\n       'I' : 'ÌÍỈĨỊ' ,\n       'O' : 'ÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢ' ,\n       'U' : 'ÙÚỦŨỤƯỪỨỬỮỰ' ,\n       'Y' : 'ỲÝỶỸỴ' ,\n       'D' : 'Đ' \n    }\n    \n    for char, replacements_str in replacements.items():\n        pattern = rf\"({char})\\1+\"\n        text = re.sub(pattern, ' ' , text)\n    pattern = rf\"(\\w)\\1+\"\n    text = re.sub(pattern, r'\\1', text)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.553141Z","iopub.execute_input":"2024-04-18T20:02:39.553464Z","iopub.status.idle":"2024-04-18T20:02:39.565732Z","shell.execute_reply.started":"2024-04-18T20:02:39.553439Z","shell.execute_reply":"2024-04-18T20:02:39.564718Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Sử dụng thư viện unicodedata để chuyển đổi các ký tự Unicode \n#tương đương thành dạng chuẩn. Ví dụ: \"Hoà\" thành \"Hòa\".\ndef normalize_unicode(text):\n    return unicodedata.normalize(\"NFC\", text)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.569031Z","iopub.execute_input":"2024-04-18T20:02:39.570256Z","iopub.status.idle":"2024-04-18T20:02:39.577224Z","shell.execute_reply.started":"2024-04-18T20:02:39.570215Z","shell.execute_reply":"2024-04-18T20:02:39.576079Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Chuẩn hóa từ vùng, từ viết tắt \n#Tạo từ điển ánh xạ các từ vựng cần chuẩn hóa sang dạng chuẩn. \n#Ví dụ: {\"okie\": \"ok\", \"okey\": \"ok\", \"authentic\": \"chuẩn chính hãng\"}.\n#Sử dụng từ điển này để thay thế các từ vựng trong văn bản.\n\ndef normalize_sentiment_words(text):\n    sentiment_word_map = {\n        'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n        'okey': ' ok ', 'ôkê': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ',\n        '⭐': 'star ', '*': 'star ', '🌟': 'star ',\n        'kg ': u' không ','not': u' không ', u' kg ': u' không ', '\"k ': u' không ',' kh ':u' không ','kô':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', '\"ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',\n        'cute': u' dễ thương ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',\n        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n        'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'store': u' cửa hàng ',\n        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n        'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n        'thick': u' thích ', 'thik': u' thích ', u' sop ': u' cửa hàng ', u' shop ': u' cửa hàng ', \n        ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',u'quả ng ':u' quảng  ',\n        'dep': u' đẹp ',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ',\n        'iu': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời',\n        ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback '\n    }\n    for word, replacement in sentiment_word_map.items():\n        text = text.replace(word, replacement)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.578623Z","iopub.execute_input":"2024-04-18T20:02:39.578971Z","iopub.status.idle":"2024-04-18T20:02:39.599015Z","shell.execute_reply.started":"2024-04-18T20:02:39.578944Z","shell.execute_reply":"2024-04-18T20:02:39.597923Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Chuẩn hóa số sao đánh giá/điểm số\ndef normalize_stars(text):\n    stars_map = {\n        '5star': 'positive ','5 sao': 'positive ','5sao': 'positive ', 'starstarstarstarstar': 'positive ',\n        '4star': 'positive ','4 sao': 'positive ','4sao': 'positive ', 'starstarstarstar': 'positive ',\n        '3star': 'negative ','3 sao': 'negative ','3sao': 'negative ', 'starstarstar': 'negative ',\n        '2star': 'negative ','2 sao': 'negative ','2sao': 'negative ', 'starstar': 'negative ',\n        '1star': 'negative ','1 sao': 'negative ','1sao': 'negative ', 'star': 'negative ',\n        '0star': 'negative ','0 sao': 'negative ','0sao': 'negative ',\n        '10 điểm' : 'positive ', ' 10đ' : 'positive ', 'mười điểm' : 'positive ', 'mừi điểm' : 'positive ',\n        '9 điểm' : 'positive ', ' 9đ' : 'positive ', 'chín điểm' : 'positive ',\n        '8 điểm' : 'positive ', ' 8đ' : 'positive ', 'tám điểm' : 'positive ',\n        '7 điểm' : 'positive ', ' 7đ' : 'positive ', 'bảy điểm' : 'positive ',\n        '6 điểm' : 'negative ', ' 6đ' : 'negative ', 'sáu điểm' : 'negative ',\n        '5 điểm' : 'negative ', ' 5đ' : 'negative ', 'năm điểm' : 'negative ',\n        '4 điểm' : 'negative ', ' 4đ' : 'negative ', 'bốn điểm' : 'negative ',\n        '3 điểm' : 'negative ', ' 3đ' : 'negative ', 'ba điểm' : 'negative ',\n        '2 điểm' : 'negative ', ' 2đ' : 'negative ', 'hai điểm' : 'negative ',\n        '1 điểm' : 'negative ', ' 1đ' : 'negative ', 'một điểm' : 'negative ',\n        '0 điểm' : 'negative ', ' 0đ' : 'negative ', 'không điểm' : 'negative ',\n        }\n    for star, label in stars_map.items():\n        text = text.replace(star, f'SCORE{label.upper()}' )\n        \n    text = ' ' .join(text.split())\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.600305Z","iopub.execute_input":"2024-04-18T20:02:39.601632Z","iopub.status.idle":"2024-04-18T20:02:39.614594Z","shell.execute_reply.started":"2024-04-18T20:02:39.601585Z","shell.execute_reply":"2024-04-18T20:02:39.613622Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from num2words import num2words\n\ndef handle_number(text):\n    # Xử lý chuyển số thành văn bản\n    words = text.split()\n    cleaned_words = []\n    for word in words:\n        try:\n            # Nếu từ kết thúc bằng dấu chấm, loại bỏ dấu chấm và xử lý số\n            if word.endswith( '.' ):\n                num = int(word.replace( ',' , '' )[:-1])\n                word = num2words(num, lang= 'vi' ) + '.' \n            else:\n                # Nếu từ chứa dấu phẩy, loại bỏ dấu phẩy và xử lý số\n                if ',' in word:\n                    word = num2words(float(word), lang= 'vi' )\n                elif '.' in word:\n                    parts = word.split( '.' ) \n                    num = '' .join(parts[0:])\n                    word = num2words(int(num), lang= 'vi' )\n                else:\n                    num = int(word)\n                    word = num2words(num, lang= 'vi' )\n        except ValueError:\n            # Nếu không thể chuyển đổi, giữ nguyên từ\n            pass\n        cleaned_words.append(word)\n    \n    # Kết hợp các từ thành câu\n    cleaned_text = ' ' .join(cleaned_words)\n    \n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:36.613022Z","iopub.execute_input":"2024-04-18T20:04:36.613613Z","iopub.status.idle":"2024-04-18T20:04:36.628156Z","shell.execute_reply.started":"2024-04-18T20:04:36.613564Z","shell.execute_reply":"2024-04-18T20:04:36.627036Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Lowercase\ndef lowercase(text):\n    return text.lower()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:39.606360Z","iopub.execute_input":"2024-04-18T20:04:39.606765Z","iopub.status.idle":"2024-04-18T20:04:39.612380Z","shell.execute_reply.started":"2024-04-18T20:04:39.606734Z","shell.execute_reply":"2024-04-18T20:04:39.610829Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## 3. Word segmentation","metadata":{}},{"cell_type":"code","source":"from pyvi import ViTokenizer\ndef Word_segmentation(text):\n    text = ViTokenizer.tokenize(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:42.068942Z","iopub.execute_input":"2024-04-18T20:04:42.069332Z","iopub.status.idle":"2024-04-18T20:04:42.154915Z","shell.execute_reply.started":"2024-04-18T20:04:42.069302Z","shell.execute_reply":"2024-04-18T20:04:42.153993Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## 4. Handle negation","metadata":{}},{"cell_type":"code","source":"def load_sentiment_lexicon(file_path):\n    #Xử lý phủ định\n    not_words = {\"không\", 'không_hề' , \"chẳng\", \"chưa\", \"không_phải\", \"chả\", \"mất\", \n                 \"thiếu\", \"vô\", \"đếch\", \"đéo\", \"kém\", \"nỏ\", \"not\",\n                 \"bớt\", \"không_bao_giờ\",\n                }\n    # Tạo tập hợp chứa các từ tích cực\n    positive_words = {\n        \"ưng_ý\", \"ưng\", \"kỹ\", \"được\", \"ô_kê\", \"ok\", \"mịn\", \"ổn\", \"xinh\", \"chúc_mừng\",\n        \"hạnh_phúc\", \"sang\", \"oách\", \"khen\", \"ổn_định\", \"cảm_ơn\", \"cám_ơn\", \"chuẩn\",\n        \"hoàn_thiện\", \"chắc_chắn\", \"sạch_sẽ\", \"hài_lòng\", \"chất_lượng\", \"hấp_dẫn\",\n        \"vui_vẻ\", \"nguyên_chất\", \"thuận_lợi\", \"có_lợi\", \"tích_cực\", \"khuyến_khích\",\n        \"tốt_hơn\", \"vị_tha\", \"sắc\", \"bén\", \"thích_hợp\", \"quý_báu\", \"sâu_sắc\",\n        \"thịnh_vượng\", \"xinh_đẹp\", \"rực_rỡ\", \"trong_sáng\", \"chấp_nhận_được\", \"khéo_léo\",\n        \"nghệ_thuật\", \"yên_tâm\", \"uyển_chuyển\", \"sôi_động\", \"nhân_đạo\", \"thân_mật\",\n        \"thoải_mái\", \"đặc_biệt\", \"toàn_diện\", \"hòa_đồng\", \"hài_hòa\", \"thuận_tiện\",\n        \"lịch_sự\", \"may_mắn\", \"may\", \"đoan_trang\", \"phấn_chấn\", \"sành_điệu\", \"sáng_suốt\",\n        \"kín_đáo\", \"mát_mẻ\", \"lấp_lánh\", \"danh_dự\", \"dễ_dàng\", \"say_mê\", \"nhiệt_tình\",\n        \"đạo_đức\", \"trung_thực\", \"trung_thành\", \"chung_thủy\", \"ngon\", \"chu_đáo\", \"ngăn_nắp\",\n        \"lành_mạnh\", \"hợp_vệ_sinh\", \"khôn\", \"khen_ngợi\", \"quý_giá\", \"kháng_khuẩn\", \"êm_tai\",\n        \"tinh_túy\", \"du_dương\", \"bổ_ích\", \"hồng_hào\", \"khỏe_khoắn\", \"khỏe_mạnh\", \"khỏe\",\n        \"mạnh\", \"săn_chắc\", \"sung_sức\", \"mạnh_khỏe\", \"trẻ_trung\", \"đùa\", \"đề_cao\", \"quản_lý\",\n        \"cánh_tay_phải\", \"nhận_dạng_được\", \"hoàn_hảo\", \"trọn_vẹn\", \"lý_tưởng\", \"dễ_an_ủi\",\n        \"đẹp\", \"duyên_dáng\", \"tuyệt_vời\", \"đáng_ngưỡng_mộ\", \"thú_vị\", \"ngọt_ngào\", \"lạc_quan\",\n        \"sinh_lợi\", \"chính_đáng\", \"khiêm_tốn\", \"minh_mẫn\", \"uy_tín\", \"vinh_dự\", \"thẳng_thắn\",\n        \"bảo_đảm\", \"màu_mỡ\", \"dễ_chịu\", \"tươi\", \"cẩn_thận\", \"đúng\", \"hiệu_quả\", \"cute\",\n        \"dễ_thương\", \"phê\", \"xịn\", \"sịn\", \"phê\", \"vui_tính\", \"chính_hãng\", \"thực_sự\",\n        \"vinh_quang\", \"thánh_thiện\", \"vui_tươi\", \"gợi_cảm\", \"cân_đối\", \"chân_thành\",\n        \"thành_thạo\", \"tinh_tế\", \"kiên_cố\", \"thân_thiện\", \"thích\", \"tỏa_sáng\", \"ngưỡng_mộ\",\n        \"phù_hợp\", \"hy_vọng\", \"tốt_đẹp\", \"tốt\", \"đẹp\", \"giỏi_giang\", \"lôi_cuốn\", \"uyên_bác\",\n        \"yêu\", \"thích_thú\", \"ái_ân\", \"chân_tình\", \"chăm_chút\", \"tuyệt\", \"nhẹ_nhõm\", \"xinh_xắn\",\n        \"giỏi\", \"khủng\", \"đạt\", \"khỏe\", \"hợp_lý\", \"hợp_lí\", \"sạch\", \"ấm\", \"mềm\", \"cải_thiện\",\n        \"tiện\", \"gọn\", \"uy_tín\", \"tin_tưởng\", \"đẹp\", \"hạnh_phúc\", \"nhạy\", \"nhạy_bén\",\n        \"pin_rất_trâu\", \"bao_mượt\", \"pin_trâu\", \"hài_lòng\", \"sạc_nhanh\", \"đẹp\", \"tuyệt_vời\"\n    }\n\n    negative_words = {\n        \"bất_lợi\", \"chán\", \"chật_hẹp\", \"chật\", \"tức_giận\", \"xấu\", \"khủng_khiếp\", \"mỏng\", \"nhầm\", \"đe_dọa\",\n        \"ghê\", \"hiểm_ác\", \"lừa_dối\", \"lừa\", \"mặn\", \"tệ_nhất\", \"bẩn_thỉu\", \"hà_khắc\", \"cay\", \"ngu_dốt\", \"hiếm\",\n        \"ngược_đãi\", \"chậm\", \"căng_thẳng\", \"thô_bạo\", \"khó_chịu\", \"khắc_nghiệt\", \"kị\", \"ghen\", \"hỗn_tạp\", \"dơ\",\n        \"liều_lĩnh\", \"dơ_bẩn\", \"thô_tục\", \"tệ_hại\", \"tệ\", \"nhầm_lẫn\", \"quá_mức\", \"xấu_số\", \"ngu_si\", \"đau_đớn\",\n        \"phàn_nàn\", \"phản_cảm\", \"tàn_phá\", \"bất_mãn\", \"hung_hăng\", \"bất_tiện\", \"hoang_sơ\", \"bẩn_thỉu\", \"dơ_bẩn\",\n        \"giả_dối\", \"đắt_đỏ\", \"đắt\", \"yếu\", \"sai_lầm\", \"lầm\", \"nghiêm_trọng\", \"đáng_ghét\", \"hỏng\", \"bất_hợp_tác\",\n        \"chán_nản\", \"yếu_đuối\", \"trục_trặc\", \"bực_bội\", \"tàn_bạo\", \"bừa_bãi\", \"lăng_nhăng\", \"thất_vọng\", \"chê_bai\",\n        \"loang_lổ\", \"tiêu_hao\", \"bất_công\", \"lang_thang\", \"khổ_sở\", \"vớ_vẩn\", \"bất_hạnh\", \"vô_tâm\", \"bù_xù\",\n        \"bừa_bộn\", \"khó\", \"gian_dối\", \"vô_dụng\", \"vô_nghĩa\", \"ác\", \"chóng_mặt\", \"là_lạ\", \"miễn_cưỡng\", \"ngu_ngốc\",\n        \"dị_ứng\", \"co_cứng\", \"hại\", \"lạm_dụng\", \"vu_khống\", \"tai_hại\", \"tồi\", \"xảo_quyệt\", \"đau_thương\", \"hỗn_loạn\",\n        \"nhức_nhối\", \"đỏ_ngầu\", \"loét\", \"sưng_tấy\", \"tấy\", \"viêm\", \"ốm_yếu\", \"khô\", \"nặng_bụng\", \"nặng_nề\", \"khàn_khàn\",\n        \"dị\", \"lật\", \"vô_vọng\", \"gian_lận\", \"xuống_cấp\", \"ứ_đọng\", \"lạnh_toát\", \"oi_ả\", \"sưng\", \"bị_nhọt\", \"có_ác_cảm\",\n        \"tàn_nhẫn\", \"mù_quáng\", \"bất_thường\", \"bất_tín\", \"gay_gắt\", \"mất_lòng\", \"bạc_bẽo\", \"thô\", \"thất_sách\",\n        \"quái_đản\", \"thù_địch\", \"xúc_phạm\", \"bất_trị\", \"yếu_đuối\", \"run\", \"gây_mê\", \"cạn_kiệt\", \"tàn_tật\", \"định_mệnh\",\n        \"hôi_thối\", \"mốc\", \"hôi\", \"gẫy\", \"lởm\", \"hắc\", \"dỏm\", \"giởm\", \"dởm\", \"nhòe\", \"chết\", \"móp\", \"mùi_thối\", \"thối\",\n        \"ràng_buộc\", \"hư_hỏng\", \"bị\", \"hư\", \"giả_mạo\", \"giả_tạo\", \"giả\", \"sợ_hãi\", \"khó_khăn\", \"xấu\", \"bốc_mùi\",\n        \"hôi_thối\", \"dã_man\", \"nham_hiểm\", \"tham_nhũng\", \"xấu_xa\", \"ủ_rũ\", \"thâm\", \"kích_ứng\", \"hờn_dỗi\", \"vu_khống\",\n        \"bôi_nhọ\", \"tác_hại\", \"tinh_nghịch\", \"khó_tiêu\", \"thong_thả\", \"nhàn_nhã\", \"trơ\", \"thối_rữa\", \"phù_phiếm\",\n        \"độc_quyền\", \"do_dự\", \"nạn_nhân\", \"rắc_rối\", \"sai\", \"định_kiến\", \"buồn_bã\", \"bứt_rứt\", \"mùi\", \"bại_hoại\",\n        \"giận_dữ\", \"báo_động\", \"phẫn_nộ\", \"ghét\", \"kênh_kiệu\", \"nhàm_chán\", \"buồn\", \"xót_xa\", \"đau_lòng\", \"khủng_khiếp\",\n        \"1star\", \"2star\", \"ngắn\", \"ác\", \"tổn_thất\", \"nặng_nề\", \"xót_xa\", \"đau_lòng\", \"bức_xúc\", \"tàn_ác\", \"ghét\",\n        \"ác_hiểm\", \"rởm\", \"tróc\", \"ám_sát\", \"lười\", \"vụn\", \"gãy\", \"hối_tiếc\", \"tiêu_cực\", \"ngu\", \"đắt\", \"hốt_hoảng\",\n        \"đểu\", \"nhái\", \"ngứa\", \"cùi\", \"hàng_lô\", \"hàng_giả\", \"phức_tạp\", \"nát\", \"mờ\", \"đơ\", \"ngỏm\", \"thất_vọng\",\n        \"lâu\", \"nặng\", \"chậm\", \"thủng\", \"hỏng\", \"trầy\", \"dão\", \"lỗi\", \"kém\", \"lùn\", \"buồn\", \"bùn\", \"thiếu\",\n        \"thất_vọng\", \"sai\", \"rách\", \"ngấy\", \"tồi_tệ\", \"mẻ\", \"ẩu\", \"cẩu_thả\", \"lộn\", \"phức_tạp\", \"ế_ẩm\", \"ế\",\n        \"sướt\", \"kém\", \"tốn_pin\", \"nóng_máy\", \"nóng\", \"thất_vọng\", \"giật_lag\", \n    }\n\n    sentiment_lexicon = {}\n    \n    raw_url = file_path\n    response = requests.get(raw_url)\n\n    if response.status_code == 200:\n        content = response.text\n    else:\n        print('Failed to retrieve the file from GitHub:', response.status_code)\n\n    header_skipped = False\n    for line in content.split('\\n'):\n        if not header_skipped:\n            if \"POS\\tID\\tPosScore\\tNegScore\\tSynsetTerms\\tGloss\" in line:\n                header_skipped = True\n            continue\n        parts = line.strip().split(\"\\t\")\n        if len(parts) >= 5:\n            word = parts[4]\n            pos_score = float(parts[2])\n            neg_score = float(parts[3])\n            if pos_score > 0.5:\n                sentiment_lexicon[word.split( '#' )[0]] = \"positive\"\n            if neg_score > 0.5:\n                sentiment_lexicon[word.split( '#' )[0]] = \"negative\"\n\n    # Bổ sung từ điển với các từ tích cực và tiêu cực\n    for word in positive_words:\n        sentiment_lexicon[word] = \"positive\"\n    for word in negative_words:\n        sentiment_lexicon[word] = \"negative\"\n\n    return not_words, positive_words, negative_words, sentiment_lexicon\n\n\n\n\nfrom pyvi import ViTokenizer\n\ndef handle_negation(text, sentiment_lexicons):\n    not_words, positive_words, negative_words, sentiment_lexicon = sentiment_lexicons\n    texts = text.split()\n    len_text = len(texts)\n\n    i = 0\n    while i < len_text:\n        cp_text = texts[i]\n        if i < len_text - 1:\n            combine_word = cp_text + '_' + texts[i+1]\n            if combine_word in not_words:\n                numb_word = min(3, len_text - i - 2)\n                for j in range(numb_word):\n                    combine_word_next = texts[i + j + 2]\n                    if combine_word_next in positive_words:\n                        texts[i] = 'NOTPOS'\n                        texts[i + j + 1] = ''\n                        texts[i + j + 2] = ''\n                    elif combine_word_next in negative_words:\n                        texts[i] = 'NOTNEG'\n                        texts[i + j + 1] = ''\n                        texts[i + j + 2] = ''\n                    else:\n                        break\n                i += numb_word \n            elif cp_text in not_words: \n                numb_word = min(2, len_text - i - 1)\n                for j in range(numb_word):\n                    if texts[i + j + 1] in positive_words:\n                        texts[i] = 'NOTPOS'\n                        texts[i + j + 1] = ''\n                    elif texts[i + j + 1] in negative_words:\n                        texts[i] = 'NOTNEG'\n                        texts[i + j + 1] = ''\n                    else:\n                        break\n                i += numb_word\n            i+=1\n        else: \n            if cp_text in positive_words:\n                texts.append('POSITIVE')\n            elif cp_text in negative_words:\n                texts.append('NEGATIVE')\n            i += 1\n\n    text = ' '.join(texts)\n    return text\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:45.219471Z","iopub.execute_input":"2024-04-18T20:04:45.220238Z","iopub.status.idle":"2024-04-18T20:04:45.268765Z","shell.execute_reply.started":"2024-04-18T20:04:45.220203Z","shell.execute_reply":"2024-04-18T20:04:45.266908Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from num2words import num2words\n\ndef process_text(text):\n    cleaned_text = clean_text(text)\n    cleaned_text = handle_number(cleaned_text)\n\n    cleaned_text = remove_punctuation(cleaned_text)\n\n    cleaned_text = lowercase(cleaned_text)\n    cleaned_text = process_emojis(cleaned_text)\n    \n    \n    cleaned_text = process_emojis(cleaned_text)\n    cleaned_text = cleaning_repeating_char(cleaned_text)\n    \n    cleaned_text = remove_elongated_chars(cleaned_text)\n    cleaned_text = normalize_unicode(cleaned_text)\n    cleaned_text = normalize_stars(cleaned_text)\n    cleaned_text = normalize_sentiment_words(cleaned_text)\n    \n    cleaned_text = Word_segmentation(cleaned_text)\n\n    file_path = \"https://raw.githubusercontent.com/tiennm0510/server_python/master/VietSentiWordnet_ver1.0.txt\"\n    sentiment_lexicon = load_sentiment_lexicon(file_path)\n    cleaned_text = handle_negation(cleaned_text, sentiment_lexicon)\n\n    #remove nốt những ký tự thừa thãi\n    cleaned_text = cleaned_text.replace(u'  ', u' ')\n    cleaned_text = cleaned_text.replace(u'\"', u' ')\n    cleaned_text = cleaned_text.replace(u'️', u'')\n    \n    cleaned_text = remove_stopword(cleaned_text)\n    \n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:49.254685Z","iopub.execute_input":"2024-04-18T20:04:49.255126Z","iopub.status.idle":"2024-04-18T20:04:49.264979Z","shell.execute_reply.started":"2024-04-18T20:04:49.255091Z","shell.execute_reply":"2024-04-18T20:04:49.263451Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"text = 'Mọi người 1 cập nhật phần mềm lại , nó sẽ bớt tốn pin, mình đã thử rồi, mọi thứ cũng ok, nhưng vân tay ko nhạy'\nprocess_text(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:52.139149Z","iopub.execute_input":"2024-04-18T20:04:52.139532Z","iopub.status.idle":"2024-04-18T20:04:52.774927Z","shell.execute_reply.started":"2024-04-18T20:04:52.139502Z","shell.execute_reply":"2024-04-18T20:04:52.773805Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'cập_nhật phần_mềm bớt tốn pin thử ok vân NOTPOS'"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5. Xử lí label","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef process_label(label):\n    label = label.replace(\"{\", \"\")\n    parts = label.strip(\"}\").split(\";\")\n    categories = []\n    sentiments = []\n    for part in parts:\n        if \"#\" in part:\n            category, sentiment = part.split(\"#\")\n            sentiment = sentiment.replace(\"}\", \"\")\n            categories.append(category)\n            sentiments.append(sentiment)\n    return pd.Series([categories, sentiments])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:06:14.398562Z","iopub.execute_input":"2024-04-18T20:06:14.399060Z","iopub.status.idle":"2024-04-18T20:06:14.407234Z","shell.execute_reply.started":"2024-04-18T20:06:14.399024Z","shell.execute_reply":"2024-04-18T20:06:14.405695Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/uit-visfd/Train.csv')\ndf[\"comment\"] = df[\"comment\"].apply(process_text)\ndf[[\"category\", \"sentiment\"]] = df[\"label\"].apply(process_label)\ndf['sentiment'] = df['sentiment'].apply(lambda x: ', '.join(x))\ndf['category'] = df['category'].apply(lambda x: ', '.join(x))\n# executed in 23 mins","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:07:15.244699Z","iopub.execute_input":"2024-04-18T20:07:15.245734Z","iopub.status.idle":"2024-04-18T20:30:46.473912Z","shell.execute_reply.started":"2024-04-18T20:07:15.245695Z","shell.execute_reply":"2024-04-18T20:30:46.472658Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data_without_diacritics = df.copy()\ndata_without_diacritics[\"comment\"] = data_without_diacritics[\"comment\"].apply(remove_diacritics)\naugmented_data = pd.concat([df, data_without_diacritics], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:31:46.681470Z","iopub.execute_input":"2024-04-18T20:31:46.682515Z","iopub.status.idle":"2024-04-18T20:31:46.950556Z","shell.execute_reply.started":"2024-04-18T20:31:46.682476Z","shell.execute_reply":"2024-04-18T20:31:46.949460Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"augmented_data.to_csv('Processed_train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:31:50.089929Z","iopub.execute_input":"2024-04-18T20:31:50.090342Z","iopub.status.idle":"2024-04-18T20:31:50.335813Z","shell.execute_reply.started":"2024-04-18T20:31:50.090312Z","shell.execute_reply":"2024-04-18T20:31:50.334578Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/uit-visfd/Test.csv')\ndf[\"comment\"] = df[\"comment\"].apply(process_text)\ndf[[\"category\", \"sentiment\"]] = df[\"label\"].apply(process_label)\ndf['sentiment'] = df['sentiment'].apply(lambda x: ', '.join(x))\ndf['category'] = df['category'].apply(lambda x: ', '.join(x))\n# df.to_csv('Processed_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:32:58.731235Z","iopub.execute_input":"2024-04-18T20:32:58.732295Z","iopub.status.idle":"2024-04-18T20:39:46.432265Z","shell.execute_reply.started":"2024-04-18T20:32:58.732244Z","shell.execute_reply":"2024-04-18T20:39:46.430956Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data_without_diacritics = df.copy()\ndata_without_diacritics[\"comment\"] = data_without_diacritics[\"comment\"].apply(remove_diacritics)\naugmented_data = pd.concat([df, data_without_diacritics], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:41:38.812034Z","iopub.execute_input":"2024-04-18T20:41:38.813331Z","iopub.status.idle":"2024-04-18T20:41:38.895274Z","shell.execute_reply.started":"2024-04-18T20:41:38.813292Z","shell.execute_reply":"2024-04-18T20:41:38.893957Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"augmented_data.to_csv('Processed_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:41:42.052919Z","iopub.execute_input":"2024-04-18T20:41:42.053337Z","iopub.status.idle":"2024-04-18T20:41:42.130215Z","shell.execute_reply.started":"2024-04-18T20:41:42.053305Z","shell.execute_reply":"2024-04-18T20:41:42.128859Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/uit-visfd/Dev.csv')\ndf[\"comment\"] = df[\"comment\"].apply(process_text)\ndf[[\"category\", \"sentiment\"]] = df[\"label\"].apply(process_label)\ndf['sentiment'] = df['sentiment'].apply(lambda x: ', '.join(x))\ndf['category'] = df['category'].apply(lambda x: ', '.join(x))\n# df.to_csv('Processed_dev.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:42:04.944563Z","iopub.execute_input":"2024-04-18T20:42:04.945539Z","iopub.status.idle":"2024-04-18T20:45:29.077812Z","shell.execute_reply.started":"2024-04-18T20:42:04.945500Z","shell.execute_reply":"2024-04-18T20:45:29.076483Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data_without_diacritics = df.copy()\ndata_without_diacritics[\"comment\"] = data_without_diacritics[\"comment\"].apply(remove_diacritics)\naugmented_data = pd.concat([df, data_without_diacritics], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:45:29.079697Z","iopub.execute_input":"2024-04-18T20:45:29.080072Z","iopub.status.idle":"2024-04-18T20:45:29.129238Z","shell.execute_reply.started":"2024-04-18T20:45:29.080040Z","shell.execute_reply":"2024-04-18T20:45:29.127924Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"augmented_data.to_csv('Processed_dev.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:45:29.130807Z","iopub.execute_input":"2024-04-18T20:45:29.131163Z","iopub.status.idle":"2024-04-18T20:45:29.172930Z","shell.execute_reply.started":"2024-04-18T20:45:29.131134Z","shell.execute_reply":"2024-04-18T20:45:29.171613Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def process_data_for_absa(data):\n    \"\"\"\n    Xử lý dữ liệu cho ABSA.\n\n    Args:\n        data (pd.DataFrame): DataFrame chứa dữ liệu đã được gắn nhãn aspect và sentiment.\n\n    Returns:\n        pd.DataFrame: DataFrame đã xử lý cho ABSA.\n    \"\"\"\n    processed_data = []\n    for index, row in data.iterrows():\n        comment = row[\"comment\"]\n        aspects = row[\"category\"].split(\", \")  # Tách các aspect\n        sentiments = row[\"sentiment\"].split(\", \")  # Tách các sentiment\n        # Tạo một sample cho mỗi cặp aspect-sentiment\n        for aspect, sentiment in zip(aspects, sentiments):\n            processed_data.append({\n                \"comment\": comment,\n                \"aspect\": aspect.strip(),\n                \"sentiment\": sentiment.strip()\n            })\n    return pd.DataFrame(processed_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T19:10:03.463792Z","iopub.status.idle":"2024-04-18T19:10:03.464181Z","shell.execute_reply.started":"2024-04-18T19:10:03.463987Z","shell.execute_reply":"2024-04-18T19:10:03.464002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# processed_data = process_data_for_absa(df)\n# processed_data","metadata":{"execution":{"iopub.status.busy":"2024-04-18T19:10:03.465740Z","iopub.status.idle":"2024-04-18T19:10:03.466410Z","shell.execute_reply.started":"2024-04-18T19:10:03.466187Z","shell.execute_reply":"2024-04-18T19:10:03.466204Z"},"trusted":true},"execution_count":null,"outputs":[]}]}