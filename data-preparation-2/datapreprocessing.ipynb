{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Table of contents\n#### 1 noise removal: \npunctuation(dáº¥u cÃ¢u), stop words (stopwordsVN), URLs and Special Characters, date time, repeating chars\n#### 2 normalization: \nElongation, accent-marks((e.g., convert all variations of \"Ã¡\" to a single form)), tá»« ngá»¯ khÃ´ng chÃ­nh thá»‘ng (slang, viáº¿t táº¯t) vÃ  cÃ¡c biáº¿n thá»ƒ vá» chÃ­nh táº£, sá»­a lá»—i chÃ­nh táº£, lowercase, num2word.\n#### 3 word segmentation\n#### 4 handle negation\n#### 5 Xá»­ lÃ­ label","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"pip install underthesea pyvi num2words py_vncorenlp pyvi","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:10.314609Z","iopub.execute_input":"2024-04-18T20:02:10.315364Z","iopub.status.idle":"2024-04-18T20:02:35.017755Z","shell.execute_reply.started":"2024-04-18T20:02:10.315327Z","shell.execute_reply":"2024-04-18T20:02:35.016776Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-6.8.0-py3-none-any.whl.metadata (14 kB)\nCollecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting num2words\n  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\nCollecting py_vncorenlp\n  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.10/site-packages (from underthesea) (8.1.7)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from underthesea) (3.2.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from underthesea) (4.66.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from underthesea) (2.31.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.3.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from underthesea) (6.0.1)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl.metadata (1.7 kB)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words) (0.6.2)\nCollecting pyjnius (from py_vncorenlp)\n  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->underthesea) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->underthesea) (2024.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (1.11.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->underthesea) (3.2.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nDownloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hDownloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: py_vncorenlp\n  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4305 sha256=253234f6975d52cd2d4bc4f2749828a3555b2d47b4930faf50c661db07b50d9e\n  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\nSuccessfully built py_vncorenlp\nInstalling collected packages: underthesea-core, python-crfsuite, pyjnius, sklearn-crfsuite, py_vncorenlp, num2words, underthesea, pyvi\nSuccessfully installed num2words-0.5.13 py_vncorenlp-0.1.4 pyjnius-1.6.1 python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6 underthesea-6.8.0 underthesea-core-1.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport unicodedata\nfrom underthesea import word_tokenize\nimport re\nimport string","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:35.019720Z","iopub.execute_input":"2024-04-18T20:02:35.020099Z","iopub.status.idle":"2024-04-18T20:02:38.969903Z","shell.execute_reply.started":"2024-04-18T20:02:35.020063Z","shell.execute_reply":"2024-04-18T20:02:38.968559Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Noise removal","metadata":{}},{"cell_type":"code","source":"# Xá»­ lÃ­ dáº¥u cÃ¢u\ndef remove_punctuation(text):\n    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n    text = text.translate(translator)\n    return text\n\ndef remove_diacritics(text):\n    text = unicodedata.normalize('NFD', text)\n    text = ''.join(c for c in text if not unicodedata.combining(c))\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:38.971276Z","iopub.execute_input":"2024-04-18T20:02:38.971857Z","iopub.status.idle":"2024-04-18T20:02:38.979395Z","shell.execute_reply.started":"2024-04-18T20:02:38.971824Z","shell.execute_reply":"2024-04-18T20:02:38.977970Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Stopwords\nimport requests\n\nraw_url = 'https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords.txt'\nresponse = requests.get(raw_url)\n\nif response.status_code == 200:\n    content = response.text\nelse:\n    print('Failed to retrieve the file from GitHub:', response.status_code)\n\n# Stopwords\nsw = content.split('\\n')\ndef remove_stopword(text):\n    text = \" \".join(x for x in text.split() if x not in sw)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:38.982822Z","iopub.execute_input":"2024-04-18T20:02:38.983366Z","iopub.status.idle":"2024-04-18T20:02:39.492923Z","shell.execute_reply.started":"2024-04-18T20:02:38.983321Z","shell.execute_reply":"2024-04-18T20:02:39.491463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# # URLs and special character\n# def clean_text(text):\n#     '''Remove special character, remove links'''\n\n#     text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    \n#     text = re.sub('\\[.*?\\]', '', text)\n# #     text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n#     text = text.replace(u'  ', u' ')\n#     text = text.replace(u'\"', u' ')\n#     text = text.replace(u'ï¸', u'')\n    \n#     return text\n\nimport re\n\ndef clean_text(text):\n    # Remove URLs, special characters and date time\n\n    # Remove URLs\n    text = re.sub(r\"https?://\\S+\", \"\", text)\n    \n    # Remove specific special characters\n    text = re.sub(r\"[!@#$%^&*(]\", \"\", text)\n    \n    # Remove dates in the format dd/mm/yyyy or dd-mm-yyyy or dd.mm.yyyy\n    text = re.sub(r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b', '', text)\n\n    # Remove dates in the format dd_mm_yy\n    text = re.sub(r'\\b\\d{1,2}[_]\\d{1,2}[_]\\d{2}\\b', '', text)\n    \n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.494524Z","iopub.execute_input":"2024-04-18T20:02:39.495132Z","iopub.status.idle":"2024-04-18T20:02:39.503231Z","shell.execute_reply.started":"2024-04-18T20:02:39.495092Z","shell.execute_reply":"2024-04-18T20:02:39.501751Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Xá»­ lÃ½ Emoji\n#Quy cÃ¡c icon vá» 2 loáº¡i emoj: TÃ­ch cá»±c hoáº·c tiÃªu cá»±c\ndef process_emojis(text):\n    emojis_list = {\n        \"ðŸ‘¹\": \"negative\", \"ðŸ‘»\": \"positive\", \"ðŸ’ƒ\": \"positive\",'ðŸ¤™': 'positive ', 'ðŸ‘': 'positive ',\n        \"ðŸ’„\": \"positive\", \"ðŸ’Ž\": \"positive\", \"ðŸ’©\": \"positive\",\"ðŸ˜•\": \"negative\", \"ðŸ˜±\": \"negative\", \"ðŸ˜¸\": \"positive\",\n        \"ðŸ˜¾\": \"negative\", \"ðŸš«\": \"negative\",  \"ðŸ¤¬\": \"negative\",\"ðŸ§š\": \"positive\", \"ðŸ§¡\": \"positive\",'ðŸ¶':'positive ',\n        'ðŸ‘Ž': 'negative ', 'ðŸ˜£': 'negative ','âœ¨': 'positive ', 'â£': 'positive ','â˜€': 'positive ',\n        'â™¥': 'positive ', 'ðŸ¤©': 'positive ', 'like': 'positive ', ':))': 'positive ', ':)': 'positive ',\n        'he he': 'positive ','hehe': 'positive ','hihi': 'positive ', 'haha': 'positive ', 'hjhj': 'positive ',\n        ' lol ': 'negative ',' cc ': 'negative ', 'huhu': 'negative ', '><': u'positive ',\n        'ðŸ’Œ': 'positive ', 'ðŸ¥°': 'positive ', 'ðŸ™†' : 'positive ', 'ðŸ˜…' : 'negative ',\n        'ðŸ¤’' : 'negative ', 'ðŸ¤¨' : 'negative ', 'ðŸ¤¦' : 'negative ', 'ðŸ˜¬' :'negative ',\n        'ðŸ”‹' : 'positive ', 'ðŸ’”' : 'negative ', 'ðŸ¤®' : 'negative ', 'âœ‹' : 'positive ',\n        'ðŸ¤£': 'positive ', 'ðŸ–¤': 'positive ', 'ðŸ¤¤': 'positive ', ':(': 'negative ', 'ðŸ˜¢': 'negative ',\n        'â¤': 'positive ', 'ðŸ˜': 'positive ', 'ðŸ˜˜': 'positive ', 'ðŸ˜ª': 'negative ', 'ðŸ˜Š': 'positive ',\n        '?': ' ? ', 'ðŸ˜': 'positive ', 'ðŸ’–': 'positive ', 'ðŸ˜Ÿ': 'negative ', 'ðŸ˜­': 'negative ',\n        'ðŸ’¯': 'positive ', 'ðŸ’—': 'positive ', 'â™¡': 'positive ', 'ðŸ’œ': 'positive ', 'ðŸ¤—': 'positive ',\n        '^^': 'positive ', 'ðŸ˜¨': 'negative ', 'â˜º': 'positive ', 'ðŸ’‹': 'positive ', 'ðŸ‘Œ': 'positive ',\n        'ðŸ˜–': 'negative ', 'ðŸ˜€': 'positive ', ':((': 'negative ', 'ðŸ˜¡': 'negative ', 'ðŸ˜ ': 'negative ',\n        'ðŸ˜’': 'negative ', 'ðŸ™‚': 'positive ', 'ðŸ˜': 'negative ', 'ðŸ˜': 'positive ', 'ðŸ˜„': 'positive ',\n        'ðŸ˜™': 'positive ', 'ðŸ˜¤': 'negative ', 'ðŸ˜Ž': 'positive ', 'ðŸ˜†': 'positive ', 'ðŸ’š': 'positive ',\n        'âœŒ': 'positive ', 'ðŸ’•': 'positive ', 'ðŸ˜ž': 'negative ', 'ðŸ˜“': 'negative ', 'ï¸ðŸ†—ï¸': 'positive ',\n        'ðŸ˜‰': 'positive ', 'ðŸ˜‚': 'positive ', ':v': 'positive ', '=))': 'positive ', 'ðŸ˜‹': 'positive ',\n        'ðŸ’“': 'positive ', 'ðŸ˜': 'negative ', ':3': 'positive ', 'ðŸ˜«': 'negative ', 'ðŸ˜¥': 'negative ',\n        'ðŸ˜ƒ': 'positive ', 'ðŸ˜¬': ' ðŸ˜¬ ', 'ðŸ˜Œ': ' ðŸ˜Œ ', 'ðŸ’›': 'positive ', 'ðŸ¤': 'positive ', 'ðŸŽˆ': 'positive ',\n        'ðŸ˜—': 'positive ', 'ðŸ¤”': 'negative ', 'ðŸ˜‘': 'negative ', 'ðŸ”¥': 'negative ', 'ðŸ™': 'negative ',\n        'ðŸ†—': 'positive ', 'ðŸ˜»': 'positive ', 'ðŸ’™': 'positive ', 'ðŸ’Ÿ': 'positive ',\n        'ðŸ˜š': 'positive ', 'âŒ': 'negative ', 'ðŸ‘': 'positive ', ';)': 'positive ', '<3': 'positive ',\n        'ðŸŒ': 'positive ',  'ðŸŒ·': 'positive ', 'ðŸŒ¸': 'positive ', 'ðŸŒº': 'positive ',\n        'ðŸŒ¼': 'positive ', 'ðŸ“': 'positive ', 'ðŸ…': 'positive ', 'ðŸ¾': 'positive ', 'ðŸ‘‰': 'positive ',\n        'ðŸ’': 'positive ', 'ðŸ’ž': 'positive ', 'ðŸ’¥': 'positive ', 'ðŸ’ª': 'positive ',\n        'ðŸ’°': 'positive ',  'ðŸ˜‡': 'positive ', 'ðŸ˜›': 'positive ', 'ðŸ˜œ': 'positive ',\n        'ðŸ™ƒ': 'negative ', 'ðŸ¤‘': 'positive ', 'ðŸ¤ª': 'positive ','â˜¹': 'negative ',  'ðŸ’€': 'negative ',\n        'ðŸ˜”': 'negative ', 'ðŸ˜§': 'negative ', 'ðŸ˜©': 'negative ', 'ðŸ˜°': 'negative ', 'ðŸ˜³': 'negative ',\n        'ðŸ˜µ': 'negative ', 'ðŸ˜¶': 'negative ', 'ðŸ™': 'negative ', 'ðŸŽ‰': 'positive '}\n    for emoji, label in emojis_list.items():\n        text = text.replace(emoji, f'EMO{label.upper()}' )\n        \n    text = ' ' .join(text.split())\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.505517Z","iopub.execute_input":"2024-04-18T20:02:39.505926Z","iopub.status.idle":"2024-04-18T20:02:39.529569Z","shell.execute_reply.started":"2024-04-18T20:02:39.505883Z","shell.execute_reply":"2024-04-18T20:02:39.528036Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Repeating chars\ndef cleaning_repeating_char(text):\n    return re.sub(r'(.)\\1+', r'\\1', text)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.531162Z","iopub.execute_input":"2024-04-18T20:02:39.531570Z","iopub.status.idle":"2024-04-18T20:02:39.541985Z","shell.execute_reply.started":"2024-04-18T20:02:39.531535Z","shell.execute_reply":"2024-04-18T20:02:39.540714Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def noise_removal(text):\n    \n    text = remove_punctuation(text)\n    text = remove_diacritics(text)\n    text = remove_stopword(text)\n    text = clean_text(text)\n    text = process_emojis(text)\n    text = cleaning_repeating_char(text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.544148Z","iopub.execute_input":"2024-04-18T20:02:39.544594Z","iopub.status.idle":"2024-04-18T20:02:39.551962Z","shell.execute_reply.started":"2024-04-18T20:02:39.544556Z","shell.execute_reply":"2024-04-18T20:02:39.550268Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 2. Normalization","metadata":{}},{"cell_type":"code","source":"# Remove cÃ¡c kÃ½ tá»± kÃ©o dÃ i: vd: Ä‘áº¹ppppppp\ndef remove_elongated_chars(text):\n    replacements = {\n       'a' : 'Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­' ,\n       'e' : 'Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡' ,\n       'i' : 'Ã¬Ã­á»‰Ä©á»‹' ,\n       'o' : 'Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£' ,\n       'u' : 'Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±' ,\n       'y' : 'á»³Ã½á»·á»¹á»µ' ,\n       'd' : 'Ä‘' ,\n       'A' : 'Ã€Ãáº¢Ãƒáº Ä‚áº°áº®áº²áº´áº¶Ã‚áº¦áº¤áº¨áºªáº¬' ,\n       'E' : 'ÃˆÃ‰áººáº¼áº¸ÃŠá»€áº¾á»‚á»„á»†' ,\n       'I' : 'ÃŒÃá»ˆÄ¨á»Š' ,\n       'O' : 'Ã’Ã“á»ŽÃ•á»ŒÃ”á»’á»á»”á»–á»˜Æ á»œá»šá»žá» á»¢' ,\n       'U' : 'Ã™Ãšá»¦Å¨á»¤Æ¯á»ªá»¨á»¬á»®á»°' ,\n       'Y' : 'á»²Ãá»¶á»¸á»´' ,\n       'D' : 'Ä' \n    }\n    \n    for char, replacements_str in replacements.items():\n        pattern = rf\"({char})\\1+\"\n        text = re.sub(pattern, ' ' , text)\n    pattern = rf\"(\\w)\\1+\"\n    text = re.sub(pattern, r'\\1', text)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.553141Z","iopub.execute_input":"2024-04-18T20:02:39.553464Z","iopub.status.idle":"2024-04-18T20:02:39.565732Z","shell.execute_reply.started":"2024-04-18T20:02:39.553439Z","shell.execute_reply":"2024-04-18T20:02:39.564718Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Sá»­ dá»¥ng thÆ° viá»‡n unicodedata Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c kÃ½ tá»± Unicode \n#tÆ°Æ¡ng Ä‘Æ°Æ¡ng thÃ nh dáº¡ng chuáº©n. VÃ­ dá»¥: \"HoÃ \" thÃ nh \"HÃ²a\".\ndef normalize_unicode(text):\n    return unicodedata.normalize(\"NFC\", text)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.569031Z","iopub.execute_input":"2024-04-18T20:02:39.570256Z","iopub.status.idle":"2024-04-18T20:02:39.577224Z","shell.execute_reply.started":"2024-04-18T20:02:39.570215Z","shell.execute_reply":"2024-04-18T20:02:39.576079Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Chuáº©n hÃ³a tá»« vÃ¹ng, tá»« viáº¿t táº¯t \n#Táº¡o tá»« Ä‘iá»ƒn Ã¡nh xáº¡ cÃ¡c tá»« vá»±ng cáº§n chuáº©n hÃ³a sang dáº¡ng chuáº©n. \n#VÃ­ dá»¥: {\"okie\": \"ok\", \"okey\": \"ok\", \"authentic\": \"chuáº©n chÃ­nh hÃ£ng\"}.\n#Sá»­ dá»¥ng tá»« Ä‘iá»ƒn nÃ y Ä‘á»ƒ thay tháº¿ cÃ¡c tá»« vá»±ng trong vÄƒn báº£n.\n\ndef normalize_sentiment_words(text):\n    sentiment_word_map = {\n        'Ã´ kÃªi': ' ok ', 'okie': ' ok ', ' o kÃª ': ' ok ',\n        'okey': ' ok ', 'Ã´kÃª': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okÃª':' ok ',\n        ' tks ': u' cÃ¡m Æ¡n ', 'thks': u' cÃ¡m Æ¡n ', 'thanks': u' cÃ¡m Æ¡n ', 'ths': u' cÃ¡m Æ¡n ', 'thank': u' cÃ¡m Æ¡n ',\n        'â­': 'star ', '*': 'star ', 'ðŸŒŸ': 'star ',\n        'kg ': u' khÃ´ng ','not': u' khÃ´ng ', u' kg ': u' khÃ´ng ', '\"k ': u' khÃ´ng ',' kh ':u' khÃ´ng ','kÃ´':u' khÃ´ng ','hok':u' khÃ´ng ',' kp ': u' khÃ´ng pháº£i ',u' kÃ´ ': u' khÃ´ng ', '\"ko ': u' khÃ´ng ', u' ko ': u' khÃ´ng ', u' k ': u' khÃ´ng ', 'khong': u' khÃ´ng ', u' hok ': u' khÃ´ng ',\n        'cute': u' dá»… thÆ°Æ¡ng ', ' vs ': u' vá»›i ', 'wa': ' quÃ¡ ', 'wÃ¡': u' quÃ¡', 'j': u' gÃ¬ ', 'â€œ': ' ',\n        ' sz ': u' cá»¡ ', 'size': u' cá»¡ ', u' Ä‘x ': u' Ä‘Æ°á»£c ', 'dk': u' Ä‘Æ°á»£c ', 'dc': u' Ä‘Æ°á»£c ', 'Ä‘k': u' Ä‘Æ°á»£c ',\n        'Ä‘c': u' Ä‘Æ°á»£c ','authentic': u' chuáº©n chÃ­nh hÃ£ng ',u' aut ': u' chuáº©n chÃ­nh hÃ£ng ', u' auth ': u' chuáº©n chÃ­nh hÃ£ng ', 'store': u' cá»­a hÃ ng ',\n        'shop': u' cá»­a hÃ ng ', 'sp': u' sáº£n pháº©m ', 'gud': u' tá»‘t ','god': u' tá»‘t ','wel done':' tá»‘t ', 'good': u' tá»‘t ', 'gÃºt': u' tá»‘t ',\n        'sáº¥u': u' xáº¥u ','gut': u' tá»‘t ', u' tot ': u' tá»‘t ', u' nice ': u' tá»‘t ', 'perfect': 'ráº¥t tá»‘t', 'bt': u' bÃ¬nh thÆ°á»ng ',\n        'time': u' thá»i gian ', 'qÃ¡': u' quÃ¡ ', u' ship ': u' giao hÃ ng ', u' m ': u' mÃ¬nh ', u' mik ': u' mÃ¬nh ',\n        'ÃªÌ‰': 'á»ƒ', 'product': 'sáº£n pháº©m', 'quality': 'cháº¥t lÆ°á»£ng','chat':' cháº¥t ', 'excelent': 'hoÃ n háº£o', 'bad': 'tá»‡','fresh': ' tÆ°Æ¡i ','sad': ' tá»‡ ',\n        'date': u' háº¡n sá»­ dá»¥ng ', 'hsd': u' háº¡n sá»­ dá»¥ng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hÃ ng ',u' sÃ­p ': u' giao hÃ ng ',\n        'beautiful': u' Ä‘áº¹p tuyá»‡t vá»i ', u' tl ': u' tráº£ lá»i ', u' r ': u' rá»“i ', u' shopE ': u' cá»­a hÃ ng ',u' order ': u' Ä‘áº·t hÃ ng ',\n        'cháº¥t lg': u' cháº¥t lÆ°á»£ng ',u' sd ': u' sá»­ dá»¥ng ',u' dt ': u' Ä‘iá»‡n thoáº¡i ',u' nt ': u' nháº¯n tin ',u' tl ': u' tráº£ lá»i ',u' sÃ i ': u' xÃ i ',u'bjo':u' bao giá» ',\n        'thick': u' thÃ­ch ', 'thik': u' thÃ­ch ', u' sop ': u' cá»­a hÃ ng ', u' shop ': u' cá»­a hÃ ng ', \n        ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' ráº¥t ',u'quáº£ ng ':u' quáº£ng  ',\n        'dep': u' Ä‘áº¹p ',u' xau ': u' xáº¥u ','delicious': u' ngon ', u'hÃ g': u' hÃ ng ', u'qá»§a': u' quáº£ ',\n        'iu': u' yÃªu ','fake': u' giáº£ máº¡o ', 'trl': 'tráº£ lá»i',\n        ' por ': u' tá»‡ ',' poor ': u' tá»‡ ', 'ib':u' nháº¯n tin ', 'rep':u' tráº£ lá»i ',u'fback':' feedback ','fedback':' feedback '\n    }\n    for word, replacement in sentiment_word_map.items():\n        text = text.replace(word, replacement)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.578623Z","iopub.execute_input":"2024-04-18T20:02:39.578971Z","iopub.status.idle":"2024-04-18T20:02:39.599015Z","shell.execute_reply.started":"2024-04-18T20:02:39.578944Z","shell.execute_reply":"2024-04-18T20:02:39.597923Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Chuáº©n hÃ³a sá»‘ sao Ä‘Ã¡nh giÃ¡/Ä‘iá»ƒm sá»‘\ndef normalize_stars(text):\n    stars_map = {\n        '5star': 'positive ','5 sao': 'positive ','5sao': 'positive ', 'starstarstarstarstar': 'positive ',\n        '4star': 'positive ','4 sao': 'positive ','4sao': 'positive ', 'starstarstarstar': 'positive ',\n        '3star': 'negative ','3 sao': 'negative ','3sao': 'negative ', 'starstarstar': 'negative ',\n        '2star': 'negative ','2 sao': 'negative ','2sao': 'negative ', 'starstar': 'negative ',\n        '1star': 'negative ','1 sao': 'negative ','1sao': 'negative ', 'star': 'negative ',\n        '0star': 'negative ','0 sao': 'negative ','0sao': 'negative ',\n        '10 Ä‘iá»ƒm' : 'positive ', ' 10Ä‘' : 'positive ', 'mÆ°á»i Ä‘iá»ƒm' : 'positive ', 'má»«i Ä‘iá»ƒm' : 'positive ',\n        '9 Ä‘iá»ƒm' : 'positive ', ' 9Ä‘' : 'positive ', 'chÃ­n Ä‘iá»ƒm' : 'positive ',\n        '8 Ä‘iá»ƒm' : 'positive ', ' 8Ä‘' : 'positive ', 'tÃ¡m Ä‘iá»ƒm' : 'positive ',\n        '7 Ä‘iá»ƒm' : 'positive ', ' 7Ä‘' : 'positive ', 'báº£y Ä‘iá»ƒm' : 'positive ',\n        '6 Ä‘iá»ƒm' : 'negative ', ' 6Ä‘' : 'negative ', 'sÃ¡u Ä‘iá»ƒm' : 'negative ',\n        '5 Ä‘iá»ƒm' : 'negative ', ' 5Ä‘' : 'negative ', 'nÄƒm Ä‘iá»ƒm' : 'negative ',\n        '4 Ä‘iá»ƒm' : 'negative ', ' 4Ä‘' : 'negative ', 'bá»‘n Ä‘iá»ƒm' : 'negative ',\n        '3 Ä‘iá»ƒm' : 'negative ', ' 3Ä‘' : 'negative ', 'ba Ä‘iá»ƒm' : 'negative ',\n        '2 Ä‘iá»ƒm' : 'negative ', ' 2Ä‘' : 'negative ', 'hai Ä‘iá»ƒm' : 'negative ',\n        '1 Ä‘iá»ƒm' : 'negative ', ' 1Ä‘' : 'negative ', 'má»™t Ä‘iá»ƒm' : 'negative ',\n        '0 Ä‘iá»ƒm' : 'negative ', ' 0Ä‘' : 'negative ', 'khÃ´ng Ä‘iá»ƒm' : 'negative ',\n        }\n    for star, label in stars_map.items():\n        text = text.replace(star, f'SCORE{label.upper()}' )\n        \n    text = ' ' .join(text.split())\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:02:39.600305Z","iopub.execute_input":"2024-04-18T20:02:39.601632Z","iopub.status.idle":"2024-04-18T20:02:39.614594Z","shell.execute_reply.started":"2024-04-18T20:02:39.601585Z","shell.execute_reply":"2024-04-18T20:02:39.613622Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from num2words import num2words\n\ndef handle_number(text):\n    # Xá»­ lÃ½ chuyá»ƒn sá»‘ thÃ nh vÄƒn báº£n\n    words = text.split()\n    cleaned_words = []\n    for word in words:\n        try:\n            # Náº¿u tá»« káº¿t thÃºc báº±ng dáº¥u cháº¥m, loáº¡i bá» dáº¥u cháº¥m vÃ  xá»­ lÃ½ sá»‘\n            if word.endswith( '.' ):\n                num = int(word.replace( ',' , '' )[:-1])\n                word = num2words(num, lang= 'vi' ) + '.' \n            else:\n                # Náº¿u tá»« chá»©a dáº¥u pháº©y, loáº¡i bá» dáº¥u pháº©y vÃ  xá»­ lÃ½ sá»‘\n                if ',' in word:\n                    word = num2words(float(word), lang= 'vi' )\n                elif '.' in word:\n                    parts = word.split( '.' ) \n                    num = '' .join(parts[0:])\n                    word = num2words(int(num), lang= 'vi' )\n                else:\n                    num = int(word)\n                    word = num2words(num, lang= 'vi' )\n        except ValueError:\n            # Náº¿u khÃ´ng thá»ƒ chuyá»ƒn Ä‘á»•i, giá»¯ nguyÃªn tá»«\n            pass\n        cleaned_words.append(word)\n    \n    # Káº¿t há»£p cÃ¡c tá»« thÃ nh cÃ¢u\n    cleaned_text = ' ' .join(cleaned_words)\n    \n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:36.613022Z","iopub.execute_input":"2024-04-18T20:04:36.613613Z","iopub.status.idle":"2024-04-18T20:04:36.628156Z","shell.execute_reply.started":"2024-04-18T20:04:36.613564Z","shell.execute_reply":"2024-04-18T20:04:36.627036Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Lowercase\ndef lowercase(text):\n    return text.lower()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:39.606360Z","iopub.execute_input":"2024-04-18T20:04:39.606765Z","iopub.status.idle":"2024-04-18T20:04:39.612380Z","shell.execute_reply.started":"2024-04-18T20:04:39.606734Z","shell.execute_reply":"2024-04-18T20:04:39.610829Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## 3. Word segmentation","metadata":{}},{"cell_type":"code","source":"from pyvi import ViTokenizer\ndef Word_segmentation(text):\n    text = ViTokenizer.tokenize(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:42.068942Z","iopub.execute_input":"2024-04-18T20:04:42.069332Z","iopub.status.idle":"2024-04-18T20:04:42.154915Z","shell.execute_reply.started":"2024-04-18T20:04:42.069302Z","shell.execute_reply":"2024-04-18T20:04:42.153993Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## 4. Handle negation","metadata":{}},{"cell_type":"code","source":"def load_sentiment_lexicon(file_path):\n    #Xá»­ lÃ½ phá»§ Ä‘á»‹nh\n    not_words = {\"khÃ´ng\", 'khÃ´ng_há»' , \"cháº³ng\", \"chÆ°a\", \"khÃ´ng_pháº£i\", \"cháº£\", \"máº¥t\", \n                 \"thiáº¿u\", \"vÃ´\", \"Ä‘áº¿ch\", \"Ä‘Ã©o\", \"kÃ©m\", \"ná»\", \"not\",\n                 \"bá»›t\", \"khÃ´ng_bao_giá»\",\n                }\n    # Táº¡o táº­p há»£p chá»©a cÃ¡c tá»« tÃ­ch cá»±c\n    positive_words = {\n        \"Æ°ng_Ã½\", \"Æ°ng\", \"ká»¹\", \"Ä‘Æ°á»£c\", \"Ã´_kÃª\", \"ok\", \"má»‹n\", \"á»•n\", \"xinh\", \"chÃºc_má»«ng\",\n        \"háº¡nh_phÃºc\", \"sang\", \"oÃ¡ch\", \"khen\", \"á»•n_Ä‘á»‹nh\", \"cáº£m_Æ¡n\", \"cÃ¡m_Æ¡n\", \"chuáº©n\",\n        \"hoÃ n_thiá»‡n\", \"cháº¯c_cháº¯n\", \"sáº¡ch_sáº½\", \"hÃ i_lÃ²ng\", \"cháº¥t_lÆ°á»£ng\", \"háº¥p_dáº«n\",\n        \"vui_váº»\", \"nguyÃªn_cháº¥t\", \"thuáº­n_lá»£i\", \"cÃ³_lá»£i\", \"tÃ­ch_cá»±c\", \"khuyáº¿n_khÃ­ch\",\n        \"tá»‘t_hÆ¡n\", \"vá»‹_tha\", \"sáº¯c\", \"bÃ©n\", \"thÃ­ch_há»£p\", \"quÃ½_bÃ¡u\", \"sÃ¢u_sáº¯c\",\n        \"thá»‹nh_vÆ°á»£ng\", \"xinh_Ä‘áº¹p\", \"rá»±c_rá»¡\", \"trong_sÃ¡ng\", \"cháº¥p_nháº­n_Ä‘Æ°á»£c\", \"khÃ©o_lÃ©o\",\n        \"nghá»‡_thuáº­t\", \"yÃªn_tÃ¢m\", \"uyá»ƒn_chuyá»ƒn\", \"sÃ´i_Ä‘á»™ng\", \"nhÃ¢n_Ä‘áº¡o\", \"thÃ¢n_máº­t\",\n        \"thoáº£i_mÃ¡i\", \"Ä‘áº·c_biá»‡t\", \"toÃ n_diá»‡n\", \"hÃ²a_Ä‘á»“ng\", \"hÃ i_hÃ²a\", \"thuáº­n_tiá»‡n\",\n        \"lá»‹ch_sá»±\", \"may_máº¯n\", \"may\", \"Ä‘oan_trang\", \"pháº¥n_cháº¥n\", \"sÃ nh_Ä‘iá»‡u\", \"sÃ¡ng_suá»‘t\",\n        \"kÃ­n_Ä‘Ã¡o\", \"mÃ¡t_máº»\", \"láº¥p_lÃ¡nh\", \"danh_dá»±\", \"dá»…_dÃ ng\", \"say_mÃª\", \"nhiá»‡t_tÃ¬nh\",\n        \"Ä‘áº¡o_Ä‘á»©c\", \"trung_thá»±c\", \"trung_thÃ nh\", \"chung_thá»§y\", \"ngon\", \"chu_Ä‘Ã¡o\", \"ngÄƒn_náº¯p\",\n        \"lÃ nh_máº¡nh\", \"há»£p_vá»‡_sinh\", \"khÃ´n\", \"khen_ngá»£i\", \"quÃ½_giÃ¡\", \"khÃ¡ng_khuáº©n\", \"Ãªm_tai\",\n        \"tinh_tÃºy\", \"du_dÆ°Æ¡ng\", \"bá»•_Ã­ch\", \"há»“ng_hÃ o\", \"khá»e_khoáº¯n\", \"khá»e_máº¡nh\", \"khá»e\",\n        \"máº¡nh\", \"sÄƒn_cháº¯c\", \"sung_sá»©c\", \"máº¡nh_khá»e\", \"tráº»_trung\", \"Ä‘Ã¹a\", \"Ä‘á»_cao\", \"quáº£n_lÃ½\",\n        \"cÃ¡nh_tay_pháº£i\", \"nháº­n_dáº¡ng_Ä‘Æ°á»£c\", \"hoÃ n_háº£o\", \"trá»n_váº¹n\", \"lÃ½_tÆ°á»Ÿng\", \"dá»…_an_á»§i\",\n        \"Ä‘áº¹p\", \"duyÃªn_dÃ¡ng\", \"tuyá»‡t_vá»i\", \"Ä‘Ã¡ng_ngÆ°á»¡ng_má»™\", \"thÃº_vá»‹\", \"ngá»t_ngÃ o\", \"láº¡c_quan\",\n        \"sinh_lá»£i\", \"chÃ­nh_Ä‘Ã¡ng\", \"khiÃªm_tá»‘n\", \"minh_máº«n\", \"uy_tÃ­n\", \"vinh_dá»±\", \"tháº³ng_tháº¯n\",\n        \"báº£o_Ä‘áº£m\", \"mÃ u_má»¡\", \"dá»…_chá»‹u\", \"tÆ°Æ¡i\", \"cáº©n_tháº­n\", \"Ä‘Ãºng\", \"hiá»‡u_quáº£\", \"cute\",\n        \"dá»…_thÆ°Æ¡ng\", \"phÃª\", \"xá»‹n\", \"sá»‹n\", \"phÃª\", \"vui_tÃ­nh\", \"chÃ­nh_hÃ£ng\", \"thá»±c_sá»±\",\n        \"vinh_quang\", \"thÃ¡nh_thiá»‡n\", \"vui_tÆ°Æ¡i\", \"gá»£i_cáº£m\", \"cÃ¢n_Ä‘á»‘i\", \"chÃ¢n_thÃ nh\",\n        \"thÃ nh_tháº¡o\", \"tinh_táº¿\", \"kiÃªn_cá»‘\", \"thÃ¢n_thiá»‡n\", \"thÃ­ch\", \"tá»a_sÃ¡ng\", \"ngÆ°á»¡ng_má»™\",\n        \"phÃ¹_há»£p\", \"hy_vá»ng\", \"tá»‘t_Ä‘áº¹p\", \"tá»‘t\", \"Ä‘áº¹p\", \"giá»i_giang\", \"lÃ´i_cuá»‘n\", \"uyÃªn_bÃ¡c\",\n        \"yÃªu\", \"thÃ­ch_thÃº\", \"Ã¡i_Ã¢n\", \"chÃ¢n_tÃ¬nh\", \"chÄƒm_chÃºt\", \"tuyá»‡t\", \"nháº¹_nhÃµm\", \"xinh_xáº¯n\",\n        \"giá»i\", \"khá»§ng\", \"Ä‘áº¡t\", \"khá»e\", \"há»£p_lÃ½\", \"há»£p_lÃ­\", \"sáº¡ch\", \"áº¥m\", \"má»m\", \"cáº£i_thiá»‡n\",\n        \"tiá»‡n\", \"gá»n\", \"uy_tÃ­n\", \"tin_tÆ°á»Ÿng\", \"Ä‘áº¹p\", \"háº¡nh_phÃºc\", \"nháº¡y\", \"nháº¡y_bÃ©n\",\n        \"pin_ráº¥t_trÃ¢u\", \"bao_mÆ°á»£t\", \"pin_trÃ¢u\", \"hÃ i_lÃ²ng\", \"sáº¡c_nhanh\", \"Ä‘áº¹p\", \"tuyá»‡t_vá»i\"\n    }\n\n    negative_words = {\n        \"báº¥t_lá»£i\", \"chÃ¡n\", \"cháº­t_háº¹p\", \"cháº­t\", \"tá»©c_giáº­n\", \"xáº¥u\", \"khá»§ng_khiáº¿p\", \"má»ng\", \"nháº§m\", \"Ä‘e_dá»a\",\n        \"ghÃª\", \"hiá»ƒm_Ã¡c\", \"lá»«a_dá»‘i\", \"lá»«a\", \"máº·n\", \"tá»‡_nháº¥t\", \"báº©n_thá»‰u\", \"hÃ _kháº¯c\", \"cay\", \"ngu_dá»‘t\", \"hiáº¿m\",\n        \"ngÆ°á»£c_Ä‘Ã£i\", \"cháº­m\", \"cÄƒng_tháº³ng\", \"thÃ´_báº¡o\", \"khÃ³_chá»‹u\", \"kháº¯c_nghiá»‡t\", \"ká»‹\", \"ghen\", \"há»—n_táº¡p\", \"dÆ¡\",\n        \"liá»u_lÄ©nh\", \"dÆ¡_báº©n\", \"thÃ´_tá»¥c\", \"tá»‡_háº¡i\", \"tá»‡\", \"nháº§m_láº«n\", \"quÃ¡_má»©c\", \"xáº¥u_sá»‘\", \"ngu_si\", \"Ä‘au_Ä‘á»›n\",\n        \"phÃ n_nÃ n\", \"pháº£n_cáº£m\", \"tÃ n_phÃ¡\", \"báº¥t_mÃ£n\", \"hung_hÄƒng\", \"báº¥t_tiá»‡n\", \"hoang_sÆ¡\", \"báº©n_thá»‰u\", \"dÆ¡_báº©n\",\n        \"giáº£_dá»‘i\", \"Ä‘áº¯t_Ä‘á»\", \"Ä‘áº¯t\", \"yáº¿u\", \"sai_láº§m\", \"láº§m\", \"nghiÃªm_trá»ng\", \"Ä‘Ã¡ng_ghÃ©t\", \"há»ng\", \"báº¥t_há»£p_tÃ¡c\",\n        \"chÃ¡n_náº£n\", \"yáº¿u_Ä‘uá»‘i\", \"trá»¥c_tráº·c\", \"bá»±c_bá»™i\", \"tÃ n_báº¡o\", \"bá»«a_bÃ£i\", \"lÄƒng_nhÄƒng\", \"tháº¥t_vá»ng\", \"chÃª_bai\",\n        \"loang_lá»•\", \"tiÃªu_hao\", \"báº¥t_cÃ´ng\", \"lang_thang\", \"khá»•_sá»Ÿ\", \"vá»›_váº©n\", \"báº¥t_háº¡nh\", \"vÃ´_tÃ¢m\", \"bÃ¹_xÃ¹\",\n        \"bá»«a_bá»™n\", \"khÃ³\", \"gian_dá»‘i\", \"vÃ´_dá»¥ng\", \"vÃ´_nghÄ©a\", \"Ã¡c\", \"chÃ³ng_máº·t\", \"lÃ _láº¡\", \"miá»…n_cÆ°á»¡ng\", \"ngu_ngá»‘c\",\n        \"dá»‹_á»©ng\", \"co_cá»©ng\", \"háº¡i\", \"láº¡m_dá»¥ng\", \"vu_khá»‘ng\", \"tai_háº¡i\", \"tá»“i\", \"xáº£o_quyá»‡t\", \"Ä‘au_thÆ°Æ¡ng\", \"há»—n_loáº¡n\",\n        \"nhá»©c_nhá»‘i\", \"Ä‘á»_ngáº§u\", \"loÃ©t\", \"sÆ°ng_táº¥y\", \"táº¥y\", \"viÃªm\", \"á»‘m_yáº¿u\", \"khÃ´\", \"náº·ng_bá»¥ng\", \"náº·ng_ná»\", \"khÃ n_khÃ n\",\n        \"dá»‹\", \"láº­t\", \"vÃ´_vá»ng\", \"gian_láº­n\", \"xuá»‘ng_cáº¥p\", \"á»©_Ä‘á»ng\", \"láº¡nh_toÃ¡t\", \"oi_áº£\", \"sÆ°ng\", \"bá»‹_nhá»t\", \"cÃ³_Ã¡c_cáº£m\",\n        \"tÃ n_nháº«n\", \"mÃ¹_quÃ¡ng\", \"báº¥t_thÆ°á»ng\", \"báº¥t_tÃ­n\", \"gay_gáº¯t\", \"máº¥t_lÃ²ng\", \"báº¡c_báº½o\", \"thÃ´\", \"tháº¥t_sÃ¡ch\",\n        \"quÃ¡i_Ä‘áº£n\", \"thÃ¹_Ä‘á»‹ch\", \"xÃºc_pháº¡m\", \"báº¥t_trá»‹\", \"yáº¿u_Ä‘uá»‘i\", \"run\", \"gÃ¢y_mÃª\", \"cáº¡n_kiá»‡t\", \"tÃ n_táº­t\", \"Ä‘á»‹nh_má»‡nh\",\n        \"hÃ´i_thá»‘i\", \"má»‘c\", \"hÃ´i\", \"gáº«y\", \"lá»Ÿm\", \"háº¯c\", \"dá»m\", \"giá»Ÿm\", \"dá»Ÿm\", \"nhÃ²e\", \"cháº¿t\", \"mÃ³p\", \"mÃ¹i_thá»‘i\", \"thá»‘i\",\n        \"rÃ ng_buá»™c\", \"hÆ°_há»ng\", \"bá»‹\", \"hÆ°\", \"giáº£_máº¡o\", \"giáº£_táº¡o\", \"giáº£\", \"sá»£_hÃ£i\", \"khÃ³_khÄƒn\", \"xáº¥u\", \"bá»‘c_mÃ¹i\",\n        \"hÃ´i_thá»‘i\", \"dÃ£_man\", \"nham_hiá»ƒm\", \"tham_nhÅ©ng\", \"xáº¥u_xa\", \"á»§_rÅ©\", \"thÃ¢m\", \"kÃ­ch_á»©ng\", \"há»n_dá»—i\", \"vu_khá»‘ng\",\n        \"bÃ´i_nhá»\", \"tÃ¡c_háº¡i\", \"tinh_nghá»‹ch\", \"khÃ³_tiÃªu\", \"thong_tháº£\", \"nhÃ n_nhÃ£\", \"trÆ¡\", \"thá»‘i_rá»¯a\", \"phÃ¹_phiáº¿m\",\n        \"Ä‘á»™c_quyá»n\", \"do_dá»±\", \"náº¡n_nhÃ¢n\", \"ráº¯c_rá»‘i\", \"sai\", \"Ä‘á»‹nh_kiáº¿n\", \"buá»“n_bÃ£\", \"bá»©t_rá»©t\", \"mÃ¹i\", \"báº¡i_hoáº¡i\",\n        \"giáº­n_dá»¯\", \"bÃ¡o_Ä‘á»™ng\", \"pháº«n_ná»™\", \"ghÃ©t\", \"kÃªnh_kiá»‡u\", \"nhÃ m_chÃ¡n\", \"buá»“n\", \"xÃ³t_xa\", \"Ä‘au_lÃ²ng\", \"khá»§ng_khiáº¿p\",\n        \"1star\", \"2star\", \"ngáº¯n\", \"Ã¡c\", \"tá»•n_tháº¥t\", \"náº·ng_ná»\", \"xÃ³t_xa\", \"Ä‘au_lÃ²ng\", \"bá»©c_xÃºc\", \"tÃ n_Ã¡c\", \"ghÃ©t\",\n        \"Ã¡c_hiá»ƒm\", \"rá»Ÿm\", \"trÃ³c\", \"Ã¡m_sÃ¡t\", \"lÆ°á»i\", \"vá»¥n\", \"gÃ£y\", \"há»‘i_tiáº¿c\", \"tiÃªu_cá»±c\", \"ngu\", \"Ä‘áº¯t\", \"há»‘t_hoáº£ng\",\n        \"Ä‘á»ƒu\", \"nhÃ¡i\", \"ngá»©a\", \"cÃ¹i\", \"hÃ ng_lÃ´\", \"hÃ ng_giáº£\", \"phá»©c_táº¡p\", \"nÃ¡t\", \"má»\", \"Ä‘Æ¡\", \"ngá»m\", \"tháº¥t_vá»ng\",\n        \"lÃ¢u\", \"náº·ng\", \"cháº­m\", \"thá»§ng\", \"há»ng\", \"tráº§y\", \"dÃ£o\", \"lá»—i\", \"kÃ©m\", \"lÃ¹n\", \"buá»“n\", \"bÃ¹n\", \"thiáº¿u\",\n        \"tháº¥t_vá»ng\", \"sai\", \"rÃ¡ch\", \"ngáº¥y\", \"tá»“i_tá»‡\", \"máº»\", \"áº©u\", \"cáº©u_tháº£\", \"lá»™n\", \"phá»©c_táº¡p\", \"áº¿_áº©m\", \"áº¿\",\n        \"sÆ°á»›t\", \"kÃ©m\", \"tá»‘n_pin\", \"nÃ³ng_mÃ¡y\", \"nÃ³ng\", \"tháº¥t_vá»ng\", \"giáº­t_lag\", \n    }\n\n    sentiment_lexicon = {}\n    \n    raw_url = file_path\n    response = requests.get(raw_url)\n\n    if response.status_code == 200:\n        content = response.text\n    else:\n        print('Failed to retrieve the file from GitHub:', response.status_code)\n\n    header_skipped = False\n    for line in content.split('\\n'):\n        if not header_skipped:\n            if \"POS\\tID\\tPosScore\\tNegScore\\tSynsetTerms\\tGloss\" in line:\n                header_skipped = True\n            continue\n        parts = line.strip().split(\"\\t\")\n        if len(parts) >= 5:\n            word = parts[4]\n            pos_score = float(parts[2])\n            neg_score = float(parts[3])\n            if pos_score > 0.5:\n                sentiment_lexicon[word.split( '#' )[0]] = \"positive\"\n            if neg_score > 0.5:\n                sentiment_lexicon[word.split( '#' )[0]] = \"negative\"\n\n    # Bá»• sung tá»« Ä‘iá»ƒn vá»›i cÃ¡c tá»« tÃ­ch cá»±c vÃ  tiÃªu cá»±c\n    for word in positive_words:\n        sentiment_lexicon[word] = \"positive\"\n    for word in negative_words:\n        sentiment_lexicon[word] = \"negative\"\n\n    return not_words, positive_words, negative_words, sentiment_lexicon\n\n\n\n\nfrom pyvi import ViTokenizer\n\ndef handle_negation(text, sentiment_lexicons):\n    not_words, positive_words, negative_words, sentiment_lexicon = sentiment_lexicons\n    texts = text.split()\n    len_text = len(texts)\n\n    i = 0\n    while i < len_text:\n        cp_text = texts[i]\n        if i < len_text - 1:\n            combine_word = cp_text + '_' + texts[i+1]\n            if combine_word in not_words:\n                numb_word = min(3, len_text - i - 2)\n                for j in range(numb_word):\n                    combine_word_next = texts[i + j + 2]\n                    if combine_word_next in positive_words:\n                        texts[i] = 'NOTPOS'\n                        texts[i + j + 1] = ''\n                        texts[i + j + 2] = ''\n                    elif combine_word_next in negative_words:\n                        texts[i] = 'NOTNEG'\n                        texts[i + j + 1] = ''\n                        texts[i + j + 2] = ''\n                    else:\n                        break\n                i += numb_word \n            elif cp_text in not_words: \n                numb_word = min(2, len_text - i - 1)\n                for j in range(numb_word):\n                    if texts[i + j + 1] in positive_words:\n                        texts[i] = 'NOTPOS'\n                        texts[i + j + 1] = ''\n                    elif texts[i + j + 1] in negative_words:\n                        texts[i] = 'NOTNEG'\n                        texts[i + j + 1] = ''\n                    else:\n                        break\n                i += numb_word\n            i+=1\n        else: \n            if cp_text in positive_words:\n                texts.append('POSITIVE')\n            elif cp_text in negative_words:\n                texts.append('NEGATIVE')\n            i += 1\n\n    text = ' '.join(texts)\n    return text\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:45.219471Z","iopub.execute_input":"2024-04-18T20:04:45.220238Z","iopub.status.idle":"2024-04-18T20:04:45.268765Z","shell.execute_reply.started":"2024-04-18T20:04:45.220203Z","shell.execute_reply":"2024-04-18T20:04:45.266908Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from num2words import num2words\n\ndef process_text(text):\n    cleaned_text = clean_text(text)\n    cleaned_text = handle_number(cleaned_text)\n\n    cleaned_text = remove_punctuation(cleaned_text)\n\n    cleaned_text = lowercase(cleaned_text)\n    cleaned_text = process_emojis(cleaned_text)\n    \n    \n    cleaned_text = process_emojis(cleaned_text)\n    cleaned_text = cleaning_repeating_char(cleaned_text)\n    \n    cleaned_text = remove_elongated_chars(cleaned_text)\n    cleaned_text = normalize_unicode(cleaned_text)\n    cleaned_text = normalize_stars(cleaned_text)\n    cleaned_text = normalize_sentiment_words(cleaned_text)\n    \n    cleaned_text = Word_segmentation(cleaned_text)\n\n    file_path = \"https://raw.githubusercontent.com/tiennm0510/server_python/master/VietSentiWordnet_ver1.0.txt\"\n    sentiment_lexicon = load_sentiment_lexicon(file_path)\n    cleaned_text = handle_negation(cleaned_text, sentiment_lexicon)\n\n    #remove ná»‘t nhá»¯ng kÃ½ tá»± thá»«a thÃ£i\n    cleaned_text = cleaned_text.replace(u'  ', u' ')\n    cleaned_text = cleaned_text.replace(u'\"', u' ')\n    cleaned_text = cleaned_text.replace(u'ï¸', u'')\n    \n    cleaned_text = remove_stopword(cleaned_text)\n    \n    return cleaned_text","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:49.254685Z","iopub.execute_input":"2024-04-18T20:04:49.255126Z","iopub.status.idle":"2024-04-18T20:04:49.264979Z","shell.execute_reply.started":"2024-04-18T20:04:49.255091Z","shell.execute_reply":"2024-04-18T20:04:49.263451Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"text = 'Má»i ngÆ°á»i 1 cáº­p nháº­t pháº§n má»m láº¡i , nÃ³ sáº½ bá»›t tá»‘n pin, mÃ¬nh Ä‘Ã£ thá»­ rá»“i, má»i thá»© cÅ©ng ok, nhÆ°ng vÃ¢n tay ko nháº¡y'\nprocess_text(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:04:52.139149Z","iopub.execute_input":"2024-04-18T20:04:52.139532Z","iopub.status.idle":"2024-04-18T20:04:52.774927Z","shell.execute_reply.started":"2024-04-18T20:04:52.139502Z","shell.execute_reply":"2024-04-18T20:04:52.773805Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'cáº­p_nháº­t pháº§n_má»m bá»›t tá»‘n pin thá»­ ok vÃ¢n NOTPOS'"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5. Xá»­ lÃ­ label","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef process_label(label):\n    label = label.replace(\"{\", \"\")\n    parts = label.strip(\"}\").split(\";\")\n    categories = []\n    sentiments = []\n    for part in parts:\n        if \"#\" in part:\n            category, sentiment = part.split(\"#\")\n            sentiment = sentiment.replace(\"}\", \"\")\n            categories.append(category)\n            sentiments.append(sentiment)\n    return pd.Series([categories, sentiments])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:06:14.398562Z","iopub.execute_input":"2024-04-18T20:06:14.399060Z","iopub.status.idle":"2024-04-18T20:06:14.407234Z","shell.execute_reply.started":"2024-04-18T20:06:14.399024Z","shell.execute_reply":"2024-04-18T20:06:14.405695Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/uit-visfd/Train.csv')\ndf[\"comment\"] = df[\"comment\"].apply(process_text)\ndf[[\"category\", \"sentiment\"]] = df[\"label\"].apply(process_label)\ndf['sentiment'] = df['sentiment'].apply(lambda x: ', '.join(x))\ndf['category'] = df['category'].apply(lambda x: ', '.join(x))\n# executed in 23 mins","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:07:15.244699Z","iopub.execute_input":"2024-04-18T20:07:15.245734Z","iopub.status.idle":"2024-04-18T20:30:46.473912Z","shell.execute_reply.started":"2024-04-18T20:07:15.245695Z","shell.execute_reply":"2024-04-18T20:30:46.472658Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data_without_diacritics = df.copy()\ndata_without_diacritics[\"comment\"] = data_without_diacritics[\"comment\"].apply(remove_diacritics)\naugmented_data = pd.concat([df, data_without_diacritics], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:31:46.681470Z","iopub.execute_input":"2024-04-18T20:31:46.682515Z","iopub.status.idle":"2024-04-18T20:31:46.950556Z","shell.execute_reply.started":"2024-04-18T20:31:46.682476Z","shell.execute_reply":"2024-04-18T20:31:46.949460Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"augmented_data.to_csv('Processed_train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:31:50.089929Z","iopub.execute_input":"2024-04-18T20:31:50.090342Z","iopub.status.idle":"2024-04-18T20:31:50.335813Z","shell.execute_reply.started":"2024-04-18T20:31:50.090312Z","shell.execute_reply":"2024-04-18T20:31:50.334578Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/uit-visfd/Test.csv')\ndf[\"comment\"] = df[\"comment\"].apply(process_text)\ndf[[\"category\", \"sentiment\"]] = df[\"label\"].apply(process_label)\ndf['sentiment'] = df['sentiment'].apply(lambda x: ', '.join(x))\ndf['category'] = df['category'].apply(lambda x: ', '.join(x))\n# df.to_csv('Processed_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:32:58.731235Z","iopub.execute_input":"2024-04-18T20:32:58.732295Z","iopub.status.idle":"2024-04-18T20:39:46.432265Z","shell.execute_reply.started":"2024-04-18T20:32:58.732244Z","shell.execute_reply":"2024-04-18T20:39:46.430956Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data_without_diacritics = df.copy()\ndata_without_diacritics[\"comment\"] = data_without_diacritics[\"comment\"].apply(remove_diacritics)\naugmented_data = pd.concat([df, data_without_diacritics], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:41:38.812034Z","iopub.execute_input":"2024-04-18T20:41:38.813331Z","iopub.status.idle":"2024-04-18T20:41:38.895274Z","shell.execute_reply.started":"2024-04-18T20:41:38.813292Z","shell.execute_reply":"2024-04-18T20:41:38.893957Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"augmented_data.to_csv('Processed_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:41:42.052919Z","iopub.execute_input":"2024-04-18T20:41:42.053337Z","iopub.status.idle":"2024-04-18T20:41:42.130215Z","shell.execute_reply.started":"2024-04-18T20:41:42.053305Z","shell.execute_reply":"2024-04-18T20:41:42.128859Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/uit-visfd/Dev.csv')\ndf[\"comment\"] = df[\"comment\"].apply(process_text)\ndf[[\"category\", \"sentiment\"]] = df[\"label\"].apply(process_label)\ndf['sentiment'] = df['sentiment'].apply(lambda x: ', '.join(x))\ndf['category'] = df['category'].apply(lambda x: ', '.join(x))\n# df.to_csv('Processed_dev.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:42:04.944563Z","iopub.execute_input":"2024-04-18T20:42:04.945539Z","iopub.status.idle":"2024-04-18T20:45:29.077812Z","shell.execute_reply.started":"2024-04-18T20:42:04.945500Z","shell.execute_reply":"2024-04-18T20:45:29.076483Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data_without_diacritics = df.copy()\ndata_without_diacritics[\"comment\"] = data_without_diacritics[\"comment\"].apply(remove_diacritics)\naugmented_data = pd.concat([df, data_without_diacritics], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:45:29.079697Z","iopub.execute_input":"2024-04-18T20:45:29.080072Z","iopub.status.idle":"2024-04-18T20:45:29.129238Z","shell.execute_reply.started":"2024-04-18T20:45:29.080040Z","shell.execute_reply":"2024-04-18T20:45:29.127924Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"augmented_data.to_csv('Processed_dev.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:45:29.130807Z","iopub.execute_input":"2024-04-18T20:45:29.131163Z","iopub.status.idle":"2024-04-18T20:45:29.172930Z","shell.execute_reply.started":"2024-04-18T20:45:29.131134Z","shell.execute_reply":"2024-04-18T20:45:29.171613Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def process_data_for_absa(data):\n    \"\"\"\n    Xá»­ lÃ½ dá»¯ liá»‡u cho ABSA.\n\n    Args:\n        data (pd.DataFrame): DataFrame chá»©a dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c gáº¯n nhÃ£n aspect vÃ  sentiment.\n\n    Returns:\n        pd.DataFrame: DataFrame Ä‘Ã£ xá»­ lÃ½ cho ABSA.\n    \"\"\"\n    processed_data = []\n    for index, row in data.iterrows():\n        comment = row[\"comment\"]\n        aspects = row[\"category\"].split(\", \")  # TÃ¡ch cÃ¡c aspect\n        sentiments = row[\"sentiment\"].split(\", \")  # TÃ¡ch cÃ¡c sentiment\n        # Táº¡o má»™t sample cho má»—i cáº·p aspect-sentiment\n        for aspect, sentiment in zip(aspects, sentiments):\n            processed_data.append({\n                \"comment\": comment,\n                \"aspect\": aspect.strip(),\n                \"sentiment\": sentiment.strip()\n            })\n    return pd.DataFrame(processed_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T19:10:03.463792Z","iopub.status.idle":"2024-04-18T19:10:03.464181Z","shell.execute_reply.started":"2024-04-18T19:10:03.463987Z","shell.execute_reply":"2024-04-18T19:10:03.464002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# processed_data = process_data_for_absa(df)\n# processed_data","metadata":{"execution":{"iopub.status.busy":"2024-04-18T19:10:03.465740Z","iopub.status.idle":"2024-04-18T19:10:03.466410Z","shell.execute_reply.started":"2024-04-18T19:10:03.466187Z","shell.execute_reply":"2024-04-18T19:10:03.466204Z"},"trusted":true},"execution_count":null,"outputs":[]}]}