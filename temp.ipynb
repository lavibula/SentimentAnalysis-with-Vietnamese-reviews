{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_preprocessed/Test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentence_dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nói tiếng anh lưu loát .</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nói tiếng lưu_loát</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giáo viên rất vui tính .</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>giáo_viên vui_tính</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cô max có tâm .</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>cô max tâm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giảng bài thu hút , dí dỏm .</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>giảng thu_hút</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giáo viên không giảng dạy kiến thức , hướng dẫ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>giáo_viên NOT giảng_dạy kiến_thức hướng_dẫn th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  topic  \\\n",
       "0                           nói tiếng anh lưu loát .          2      0   \n",
       "1                           giáo viên rất vui tính .          2      0   \n",
       "2                                    cô max có tâm .          2      0   \n",
       "3                       giảng bài thu hút , dí dỏm .          2      0   \n",
       "4  giáo viên không giảng dạy kiến thức , hướng dẫ...          0      0   \n",
       "\n",
       "                                    sentence_dropped  \n",
       "0                                 nói tiếng lưu_loát  \n",
       "1                                 giáo_viên vui_tính  \n",
       "2                                         cô max tâm  \n",
       "3                                     giảng thu_hút   \n",
       "4  giáo_viên NOT giảng_dạy kiến_thức hướng_dẫn th...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"wonrax/phobert-base-vietnamese-sentiment\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_label(label):\n",
    "    if isinstance(label, list):\n",
    "        return [map_label(l) for l in label]\n",
    "    if label == 'POS':\n",
    "        return 2\n",
    "    elif label == 'NEU':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = data['sentiment'].tolist()\n",
    "topic = data['topic'].tolist()\n",
    "topicname = np.unique(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([v for v in data['sentence_dropped'] if not isinstance(v, str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(data['sentence_dropped'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [map_label(pred['label']) for pred in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by topic\n",
    "group_pred = [[] for i in topicname]\n",
    "group_gt = [[] for i in topicname]\n",
    "for p, g, t in zip(pred, gt, topic):\n",
    "    group_pred[t].append(p)\n",
    "    group_gt[t].append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.30      0.45       791\n",
      "           1       0.07      0.72      0.13        71\n",
      "           2       0.88      0.79      0.83      1424\n",
      "\n",
      "    accuracy                           0.62      2286\n",
      "   macro avg       0.62      0.60      0.47      2286\n",
      "weighted avg       0.86      0.62      0.68      2286\n",
      "\n",
      "Topic 1: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.23      0.37       415\n",
      "           1       0.12      0.83      0.20        47\n",
      "           2       0.46      0.56      0.51       108\n",
      "\n",
      "    accuracy                           0.34       570\n",
      "   macro avg       0.51      0.54      0.36       570\n",
      "weighted avg       0.80      0.34      0.38       570\n",
      "\n",
      "Topic 2: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.49      0.66       138\n",
      "           1       0.04      1.00      0.07         2\n",
      "           2       0.10      0.40      0.15         5\n",
      "\n",
      "    accuracy                           0.50       145\n",
      "   macro avg       0.37      0.63      0.29       145\n",
      "weighted avg       0.94      0.50      0.63       145\n",
      "\n",
      "Topic 3: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.35      0.47        57\n",
      "           1       0.37      0.56      0.45        39\n",
      "           2       0.60      0.71      0.65        48\n",
      "\n",
      "    accuracy                           0.53       144\n",
      "   macro avg       0.56      0.54      0.52       144\n",
      "weighted avg       0.58      0.53      0.52       144\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy, presicion, recall, f1 using sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "[print(f\"Topic {t}: \\n{classification_report(group_gt[t], group_pred[t])}\") for t in topicname]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
